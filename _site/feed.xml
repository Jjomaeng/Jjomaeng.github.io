<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">MinPy</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://localhost:4000" />
<updated>2022-03-21T17:00:17+09:00</updated>
<id>http://localhost:4000/</id>
<author>
  <name>Cho min Hee</name>
  <uri>http://localhost:4000/</uri>
  <email>aezjk56@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[2.1 Binary Variables]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-2.1-Binary-Variables/" />
  <id>http://localhost:4000/articles/[PRML]2.1 Binary Variables</id>
  <published>2022-03-02T04:01:50+09:00</published>
  <updated>2022-03-02T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;이 장에서 논의할 분포의 역할들 중 하나는 한정된 수의 관찰 집합 x1,….,xn이 주어졌을 때 확률 변수 x의 확률 분포 p(x)를 모델링하는 것이다. 이를 &lt;b&gt;밀도 추정 문제 &lt;/b&gt; 라고 한다.
이 장의 목표를 위해서 데이터 포인트들은 독립적이며, 동일하게 분포되어 있다고 가정할 것이다.&lt;/p&gt;

&lt;p&gt;우선, 이산 확률 변수의 이항 분포와 다항 분포를 살펴보고 그 다음으로 연속 확률 변수의 가우시안 분포에 대해 논의할 것이다. 이 분포들은 매개변수 분포의 예다. 
이러한 모델을 밀도 추정 문제에 적용하기 위해서는 관찰된 데이터 집합을 바탕으로 적절한 매개변숫값을 구하는 과정이 필요하다.&lt;br /&gt;
두 가지 관점에서 살펴보자&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;빈도적 관점 : 어떤 특정 기준을 최적화하는 방법으로 매개변수를 찾는다. 최적화 기준의 예로 가능도 함수가 있다.&lt;/li&gt;
  &lt;li&gt;베이지안 관점 : 매개변수에 대한 사전 분포를 바탕으로 관측된 데이터 집합이 주어졌을 때의 해당 사후분포를 계산한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;켤레 사전 확률이 중요한 역할을 한다는 것도 살펴볼 것이다. 켤레 사전 확률은 사후 확률이 사전 확률과 같은 함수적 형태를 띠도록 만들어준다. 그 결과 , 베이지안 분석이 매우 단순해진다.&lt;/p&gt;

&lt;p&gt;매개변수적인 접근법의 한계점도 존재한다. 분포가 특정한 함수 형태를 띠고있다고 가정하지만 몇몇 적용 사례의 경우에는 이 가정이 적절하지 않다. 이런 경우, 비매개변수적 밀도 추정 방식을 대안으로 활용할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;이산-확률-변수&quot;&gt;이산 확률 변수&lt;/h4&gt;

&lt;p&gt;하나의 이진 확률 변수 \( x \in (0,1) \)을 고려해 보자. 0과 1이 나올 확률이 동일하지 않다고 가정하면 이때 x = 1일 확률은 매개변수 \( \mu \)를 통해 다음과 같이 표현할 수 있다.
\[ p(x = 1 \mid \mu) = \mu (0 \leq \mu \leq 1)\]
\[ p(x = 0 \mid \mu ) = 1 - \mu \]&lt;/p&gt;

&lt;p&gt;따라서 x에 대한 확률은 다음의 형태로 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ Bern(x \mid \mu ) = \mu^{x}(1 - \mu)^{1-x} \]&lt;/p&gt;

&lt;p&gt;이것을 &lt;b&gt; 베르누이 분포 &lt;/b&gt;라고 한다. 베르누이 분포는 정규화되어 있으며, 그 평균과 분산이 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(x) = \mu \]
\[ var(x) = \mu(1-\mu) \]&lt;/p&gt;

&lt;p&gt;x의 관극값이 데이터 집합 \( D = (x_{1},…..x_{N})\)이 주어졌다고 하자. 관측값들이 \( p(x \mid \mu)\)에서 독립적으로 추출되었다는 가정하에 \( \mu \)함수로써 가능도 함수를 구성할 수 있다.
\[ p(D \mid \mu ) = \prod_{n=1}^{N}p(x_{n} | \mu) = \prod_{n=1}^{N}\mu^{x_{n}}(1-\mu)^{1 - x_{n}} \]&lt;/p&gt;

&lt;p&gt;빈도적 관점에서는 가능도 함수를 최대화하는 \( \mu \)를 찾아서 \( \mu \)값을 추정할 수 있다. 베르누이 분포의 경우 로그 가능도 함수는 다음으로 주어진다.&lt;/p&gt;

&lt;p&gt;\[ lnp(D \mid \mu ) = \sum_{n=1}^{N}lnp(x_{n} \mid \mu) = \sum_{n=1}^{N}(x_{n}ln\mu + (1-x_{n})ln(1-\mu)) \]&lt;/p&gt;

&lt;p&gt;로그 가능도함수는 오직 관측값들의 합인 \(\sum_{n}x_{n}\)을 통해서만 N개의 관측값 \(x_{n} \)과 연관된다는 점에 주목할 필요가 있다. 이 합은 &lt;b&gt; 충분 통계량 &lt;/b&gt;의 예시 중 하나다.&lt;/p&gt;

&lt;p&gt;\( lnp(D \mid \mu )\)을 \(\mu \)에 대해 미분하고 이를 0과 같다고 놓으면 다음과 같은 최대 가능도 추정값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_{n}\]&lt;/p&gt;

&lt;p&gt;이는 &lt;b&gt; 표본 평균 &lt;/b&gt;이라고도 불린다. 데이터에서 x = 1인 관찰값의 수를 m이라고 하면 다음의 형태로 다시 적을 수 있다. 
\[ \mu_{ML} = \frac{m}{N} \]&lt;/p&gt;

&lt;p&gt;즉, 최대가능도 체계하에에서 동전으로 예시를 들면, 동전의 앞면이 나올 확률은 데이터 집합에서 앞면이 나온 비율로 주어지게 되는 것이다.&lt;/p&gt;

&lt;p&gt;하지만 최대가능도를 사용할 경우 과적합이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;동전을 세 번 던졌는데 세 번 다 앞면이 나온 경우를 생각해보자. 그러면 N = m = 3이고 따라서 \( \mu_{ML} = 1 \)이 된다( 이 경우 앞으로 던지는 모든 동전이 앞면으로 나올 것이라고 예측하는 것이다! ) 이것이 실제로 최대 가능도를 사용했을 경우 발생할 수 있는 극단적인 사례다.( 이후에 사전 분포를 바탕으로 나은 결과를 도출할 수 있다.)&lt;/p&gt;

&lt;p&gt;크기 N의 데이터가 주어졌을 때 x = 1인 관측값의 수 m에 대해서도 분포를 생각할 수 있다. 이를 &lt;b&gt; 이항 분포 &lt;/b&gt;라 한다. 위에서 구한 가능도 함수로부터 이항 분포는 \( \mu^{m}(1 - \mu)^{N - M}\)에 비례한다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;정규화 계수를 구하기 위해서 동전 던지기로 예시를 들면, 동전 던지기를 N번 했을 때 앞면이 m번 나올 수 있는 가능한 모든 가짓수를 구해야 한다. 따라서 이항 분포를 다음과 같이 적을 수 있다.
\[Bin(m \mid N,\mu) = \binom{N}{m}\mu^{m}(1-\mu)^{N-m} \]&lt;/p&gt;

&lt;p&gt;여기서 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ \binom{N}{m} \equiv \frac{N!}{(N-m)!m!} \]&lt;/p&gt;

&lt;p&gt;\( \binom{N}{m} \)은 N개의 물체들 중 m개의 물체를 선별하는 가짓수를 구한 것이다. 이해를 위해 N = 10이고 \(\mu \)= 0.25일 때의 이항 분포의 히스토그램은 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/8.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;베타-분포&quot;&gt;베타 분포&lt;/h4&gt;

&lt;p&gt;이미 살펴본 방법들은 데이터 수가 적을 때 심각한 과적합이 일어나기 쉽다(동전 던지기 예시를 생각해보자!)&lt;/p&gt;

&lt;p&gt;이 문제에 베이지안적으로 접근하기 위해서는 매개변수 \( \mu \)에 대한 사전 분포 \( p(\mu) \)를 도입하는 것이 필요하다.&lt;/p&gt;

&lt;p&gt;가능도 함수가 \( \mu^{x}(1-x)^{1-x}\)의 형태를 가지는 인자들의 곱의 형태를 띠고 있다는 것에 주목해보면, 만약 \(\mu \)dhk \( (1 - \mu) \)의 거듭제곱에 비례하는 형태를 사전 분포에 선택한다면, 사전 확률과 가능도 함수의 곱에 비례하는 사후 분포 역시 사전 분포와 같은 함수적 형태를 가지게 될 것이다. 이러한 성질을 &lt;b&gt; 켤레성&lt;/b&gt;이라고 한다. ( 켤레성에 대한 이해를 돕고자 켤레의 수학적 의미를 설명하면, 두 개의 점,선,도형,수 등이 서로 대칭이거나 보완적인 관계에 있는 경우 켤레라고 한다.)&lt;/p&gt;

&lt;p&gt;지금까지의 논의를 바탕삼아 사전 분포로 베타 분포를 사용할 것이다.( &lt;a href=&quot;https://jjomaeng.github.io/blog/베타-분포/&quot;&gt;왜 베타 분포를 사용하는 지에 대한 자세한 설명은 여기에 작성하였습니다!&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;베타 분포는 다음의 형태를 가진다.
\[ Beta(\mu \mid a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\]&lt;/p&gt;

&lt;p&gt;\( \Gamma(x) \)는 다음과 같이 정의된다. (&lt;a href=&quot;https://jjomaeng.github.io/blog/감마-분포/&quot;&gt;감마 함수에 대한 자세한 내용은 여기에 작성하였습니다!&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;\[ \Gamma(x) = \int_{0}^{\infty } u^{x-1} e^{-1} du \]&lt;/p&gt;

&lt;p&gt;베타 분포의 계수들은 베타 분포가 정규화되도록 한다.&lt;/p&gt;

&lt;p&gt;\[ \int_{0}^{1}Beta(\mu \mid a,b) d\mu = 1 \]&lt;/p&gt;

&lt;p&gt;베타 분포의 평균과 분산은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(\mu) = \frac{a}{a+b} \]
\[ var(\mu) = \frac{ab}{(a+b)^{2}(a+b+1)} \]&lt;/p&gt;

&lt;p&gt;매개변수 a와 b는 이들이 매개변수 \( \mu \)의 분포를 조절하기 때문에 &lt;b&gt;초매개변수&lt;/b&gt;라고 불린다.&lt;/p&gt;

&lt;p&gt;이제 베타 사전 분포와 이항 가능도 함수를 곱한 후 정규화를 시행함으로써 \( \mu \)의 사후 분포를 구할 수 있다.
\( \mu \)와 관련되어 있는 인자들만 남기면 사후 분포가 다음의 형태를 가지게 되는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(\mu \mid m,l,a,b) \propto \mu^{m+a-1}(1 - /m)^{l+b-1}\]&lt;/p&gt;

&lt;p&gt;여기서 l = N -m이며 동전 던기기 예시에서 ‘뒷면’의 개수에 해당한다.&lt;/p&gt;

&lt;p&gt;사후 분포의 식은 사전 분포와 \(\mu \)에 대해서 같은 함수적 종속성을 가지고 있다는 것을 확인할 수 있다. 이 사실이 가능도 함수에 대해서 사전 분포가 켤레성을 가지고 있다는 것을 반영한다. 
실제로 사후 분포는 또 다른 베타 분포일 뿐이다.
그러면 사후 분포의 정규화 계수는 베타 분포의 식을 참고하여 구할 수 있다. 그 결과 다음을 얻게 된다.&lt;/p&gt;

&lt;p&gt;\[ p(\mu \mid m,l,a,b) = \frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)} \mu^{m+a-1}(1-\mu)^{l+b-1}\]&lt;/p&gt;

&lt;p&gt;\[ \]&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-2.1-Binary-Variables/&quot;&gt;2.1 Binary Variables&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on March 02, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.6 Information Theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.6-Information-Theory/" />
  <id>http://localhost:4000/articles/[PRML]1.6 Information Theory</id>
  <published>2022-03-01T04:01:50+09:00</published>
  <updated>2022-03-01T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.6-Information-Theory/&quot;&gt;1.6 Information Theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on March 01, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.5 Decision Theory(2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.5-Decision-Theory(2)/" />
  <id>http://localhost:4000/articles/[PRML]1.5 Decision Theory(2)</id>
  <published>2022-02-28T04:01:50+09:00</published>
  <updated>2022-02-28T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;패턴 인식에서 ‘불확실성’은 측정할 때의 노이즈를 통해서도 발생하고 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.
따라서, 확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해 준다.&lt;/p&gt;

&lt;p&gt;예시를 들어보자&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이 예시에서는 X,Y라는 두 가지 확률 변수가 존재한다. X는 \(x_{i} \) (i = 1,….,M)중 아무 값이나 취할 수 있고 Y는 \(y_{j} \) (j = 1,…,L)중 아무 값이나 취할 수 있다. 또한, X와 Y각각에서 표본을 추출하는 시도를 N번 한다고 가정한다.
\(n_{i,j} \)는 \( X = x_{i}, Y = y_{j} \) 인 시도 개수를 의미하며, \(c_{i} \)는 Y 값과는 상관없이 \(X= x_{i} \)인 시도의 숫자, \(r_{j} \)는  X값과 상관없이 \(Y=y_{j} \)인 시도의 숫자를 의미한다.&lt;/p&gt;

&lt;p&gt;\( X = x_{i}, Y = y_{j} \) 일 결합 확률은 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i},Y = y_{i}) = \frac{n_{i,j}}{N} \]&lt;/p&gt;

&lt;p&gt;비슷하게 Y값과 무관하게 X가 \(x_{i} \)값을 가질 확률을 다음과 같다&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) =\frac{c_{i}}{N} \]&lt;/p&gt;

&lt;p&gt;이 두 식을 이용하여 다음을 도출해 낼 수 있다.&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) = \sum_{j=1}^{L}p(X = x_{i},Y = y_{j}) \]&lt;/p&gt;

&lt;p&gt;이것이 확률의 &lt;b&gt;합의 법칙&lt;/b&gt;이다. 여기서 \(P(X = x_{i}) \)는 주변 확률이라 불린다.&lt;/p&gt;

&lt;p&gt;여기서 \(X = x_{i} \)인 사례들만 고려해보자. 그들 중에서 \(Y = y_{i} \)인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 \(p(Y = y_{i} | X = x_{i}) \)로 적을 수 있으며
이를 &lt;b&gt;조건부 확률&lt;/b&gt;이라고 부른다&lt;/p&gt;

&lt;p&gt;\[ p(Y = y_{i} \mid X = x_{i}) = \frac{n_{i,j}}{c_{i}} \]&lt;/p&gt;

&lt;p&gt;지금까지의 식을 이용해서 다음의 관계를 도출할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i} \mid Y = x_{j}) = \frac{n_{i,j}}{c_{i}} = \frac{n_{i,j}}{c_{i}}\cdot \frac{c_{i}}{N} = p(Y = y_{j} \mid X = x_{i})p(X=x_{i}) \]&lt;/p&gt;

&lt;p&gt;이것이 바로 확률의&lt;b&gt; 곱의 법칙&lt;/b&gt;이다&amp;lt;/p&amp;gt;&lt;/p&gt;

&lt;p&gt;이제, 곱의 법칙과 합의 법칙, 대칭성 p(X,Y) = p(Y,X)로 부터 조건부 확률 간의 관계인 다음 식을 도출해 낼 수 있다.
(여기서 부터는 간단하게 확률 변수 X에서 분포를 표현할 때는 p(X)라 적고 특정 값 xi에서의 분포를 표현할 때는 \(p(x_{i}) \)로 적기로 한다)&lt;/p&gt;

&lt;p&gt;\[p(Y \mid X) = \frac{p(X\mid Y)p(Y)}{p(X)} = \frac{p(X\mid Y)p(Y)}{\sum_{Y}p(X\mid Y)p(Y)} \]&lt;/p&gt;

&lt;p&gt;이를 &lt;b&gt;베이즈 정리&lt;/b&gt;라고 한다( 책의 전반에 걸쳐 중요한 역할을 한다)&lt;/p&gt;

&lt;p&gt;여기서 분모는 왼쪽 항을 모든 Y값에 대하여 합했을 때 1이 되도록 하는 역할을 한다.
베이지안 정리는 다음과 같이 해석할 수 있다.
확률 p(A|B)를 알고 있을 때, 관계가 정반대인 확률 p(B|A)를 계산하는 것으로 여기서 P(B)는 사전 확률, p(B|A)는 사후 확률에 해당한다.
여기서, 두 확률 변수가 독립이라면, p(X,Y) = p(X)p(Y) 이다.&lt;/p&gt;

&lt;h4 id=&quot;확률-밀도&quot;&gt;확률 밀도&lt;/h4&gt;

&lt;p&gt;이번에는 연속적인 변수에서의 확률에 대해 알아본다.&lt;/p&gt;

&lt;p&gt;만약 실수 변수 x가 (x,x+δx)구간 안의 값을 가지고 그 변수의 확률이 p(x)δx로 주어진다면, p(x)를 x의 확률 밀도라고 부른다.
이때, x가 (a,b) 구간 사이의 값을 가질 확률은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ p(x \in (a,b)) = \int_{a}^{b}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서, 확률은 양의 값을 가지고 x의 값은 실축선상에 존재해야 하기 때문에 다음의 두 조건을 만족시켜야 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\( p(x) \geq 0 \)&lt;/li&gt;
  &lt;li&gt;\( \int_{-\infty }^{\infty}p(x)dx = 1 \)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;누적-분포-함수&quot;&gt;누적 분포 함수&lt;/h4&gt;

&lt;p&gt;x가 (-∞,z) 범위에 속할 확률은 &lt;b&gt;누적 분포 함수 &lt;/b&gt; 로 표현된다.&lt;/p&gt;

&lt;p&gt;\[ P(z) = \int_{-\infty }^{z}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서 P’(x) = p(x)이다.&lt;/p&gt;

&lt;p&gt;만약 x가 이산 변수일 경우 p(x)를  &lt;b&gt; 확률 질량 함수 &lt;/b&gt;라고 부르기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;기댓값&quot;&gt;기댓값&lt;/h4&gt;
&lt;p&gt;기댓값은 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값을 의미한다. 이산 분포의 경우 기댓값은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(f) = \sum_{x}p(x)f(x) \]&lt;/p&gt;

&lt;p&gt;여기서 p(x)는 각 x값에 해당하는 확률이며 이것을 가중치로 사용한 가중 평균을 구하는 것으로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;연속 변수의 경우에는 해당 확률 밀도에 대해 적분을 시행해서 기댓값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(f) = \int p(x)f(x)dx \]&lt;/p&gt;

&lt;p&gt;공분산에 해당하는 특징은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E[aX + b] = aE[X] + b&lt;/li&gt;
  &lt;li&gt;E[X + Y] = E[X] + E[Y]&lt;/li&gt;
  &lt;li&gt;E[XY] = E[X]E[Y]&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;공분산&quot;&gt;공분산&lt;/h4&gt;

&lt;p&gt;공분산을 설명하기 앞서 분산부터 설명하면, f(x)의 분산은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ var(f) = E((f(x) - E(f(x)))^{2}) \]&lt;/p&gt;

&lt;p&gt;이는 f(x)가 평균값 E[f(x)]로부터 전반적으로 얼마나 멀리 분포되었는지를 나타내는 값이다.&lt;/p&gt;

&lt;p&gt;이를 전개하여 정리하면 다음과 같다. (식의 이해를 돕기 위하여 상수인 E[f(x)] 부분을  μ라 표현)&lt;/p&gt;

&lt;p&gt;\( var(f) = E(f(x)^{2} -2\mu f(x) +\mu^{2})) \)  -&amp;gt; 공분산 특징 첫 번째 이용&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) -2\mu E(f(x)) +\mu^{2} \)&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) - E(f(x))^{2} \)&lt;/p&gt;

&lt;p&gt;여기서 변수 x 그 자체에도 고려가능하다.&lt;/p&gt;

&lt;p&gt;다음으로 두 개의 확률 변수 x 와 y에 대해서 공분산은 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ cov(x,y) = E((x - E(x))(y - E(y)) \]
\[= E(xy) - E(x)E(y) \]&lt;/p&gt;

&lt;p&gt;이는 x값과 y값이 얼마나 함께 같이 변동하는가에 대한 지표이며 만얀 x,y가 서로 독립적일 경우 공부산값은 0으로 간다.&lt;/p&gt;

&lt;p&gt;베이지안 확률에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.5-Decision-Theory(2)/&quot;&gt;1.5 Decision Theory(2)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 28, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.5 Decision Theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.5-Decision-Theory/" />
  <id>http://localhost:4000/articles/[PRML]1.5 Decision Theory</id>
  <published>2022-02-27T04:01:50+09:00</published>
  <updated>2022-02-27T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.5-Decision-Theory/&quot;&gt;1.5 Decision Theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 27, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.3 Model Selection - 1.4 The Curse of Dimensionality]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.3-Model-Selection-1.4-The-Curse-of-Dimensionality/" />
  <id>http://localhost:4000/articles/[PRML]1.3 Model Selection - 1.4 The Curse of Dimensionality</id>
  <published>2022-02-26T07:08:50+09:00</published>
  <updated>2022-02-26T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.3-Model-Selection-1.4-The-Curse-of-Dimensionality/&quot;&gt;1.3 Model Selection - 1.4 The Curse of Dimensionality&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 26, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2 Probability theory(3)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory(3)/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory(3)</id>
  <published>2022-02-26T07:08:50+09:00</published>
  <updated>2022-02-26T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;이번에는 곡선 피팅 문제를 확률적 측면에서 살펴보자.&lt;/p&gt;

&lt;p&gt;곡선 피팅 문제의 목표는 N개의 입력값 \( X = (x1,….xn)^{T} \) 과 해당 표적값 \( t = (t1,…tn)^{T} \)가 주어진 상황에서 새로운 입력 변수 x가 
주어졌을 때 그에 대한 타깃 변수 t를 예측해 내는 것이다.
확률 분포를 이용해서 타깃 변수의 값에 대한 불확실성을 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;먼저, 주어진 x값에 대한 t값이 y(x,w)를 평균으로 가지는 가우시안 분포를 가진다고 가정한다(y(x,w)에 대한 설명은 1.1 참고 )
이를 바탕으로 다음의 조건부 분포를 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ “p(t \mid x,\textbf{w},b) = N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]&lt;/p&gt;

&lt;p&gt;여기서 β는 정밀도 매개변수로써 분포의 표본의 역수에 해당한다.
이 식을 도식화해 확인해보면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/7.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이제 훈련 집합 {X,t}를 바탕으로 최대 가능도 방법을 이용해서 알려지지 않은 매개변수 w와 β를 구해보도록 하자.
데이터는 위의 식에서 독립적으로 추출했다고 가정하면(i.i.d), 가능도 함수는 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ p(\textbf{t} \mid \textbf{x},\textbf{w},b) = \prod_{n=1}^{N}N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]&lt;/p&gt;

&lt;p&gt;계산의 편의를 위해 로그를 취해 로그 가능도 함수를 얻으면 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ ln p(\textbf{t} \mid \textbf{x},\textbf{w},b) = -\frac{\beta }{2}\sum_{n= 1}^{N}{(y(x_{n},\textbf{w})-t_{n})}^{2} + \frac{N}{2}ln\beta - \frac{N}{2}ln(2\pi) \]&lt;/p&gt;

&lt;p&gt;다항식 계수(w)의 최대 가능도 해를 구해보면 w와 관련된 것은 오른쪽 식의 맨 왼쪽만 해당한다. 따라서 음의 로그이기 때문에 이를 최소화하는 것이다. 즉 가능도 함수를 최대화하려는 시도의 결과로 제곱합 오차 함수를 유도할 수 있는 것이다.&lt;/p&gt;

&lt;p&gt;마찬가지로 가우시안 조건부 분포의 정밀도 매개변수 β를 결정하는 데도 최대 가능도 방법을 사용할 수 있다. 로그 가능도를 β에 대해 최대화하면 다음의 식이 도출된다.&lt;/p&gt;

&lt;p&gt;\[ \frac{1}{B_{ML}} = \frac{1}{N}\sum_{n = 1}^{N}(y(x_{n},w_{ML})-t_{n})^{2} \]&lt;/p&gt;

&lt;p&gt;매개변수 w와  β를 구했으니, 이제 이를 바탕으로 새로운 변수 x에 대해 예측값을 구할 수 있다.
확률모델을 사용하고 있으므로 예측값은 t에 대한 예측 분포로 표현될 것이다(점 X)
최대 가능도 매개변수들을 식(1)에 대입하면 다음을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \[ p(t \mid x,\textbf{w}&lt;em&gt;{ML},\beta&lt;/em&gt;{ML}) = (t \mid y(x,w_{ML})) \]&lt;/p&gt;

&lt;p&gt;이제 다항 계수 w에 대한 사전 분포를 도입할 것이다. 문제의 단순화를 위해서 다음 형태를 지닌 가우시안 분포를 사용할 것이다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory(3)/&quot;&gt;1.2 Probability theory(3)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 26, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2. Probability theory (2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory(2)/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory(2)</id>
  <published>2022-02-25T07:08:50+09:00</published>
  <updated>2022-02-25T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;지금까지 확률을 ‘반복 가능한 임의의 사건의 빈도수’라는 측면에서 살펴보았다. 이러한 해석을 고전적 또는 빈도적 관점이라 일컫는다.
이번에는 더 포괄적인 베이지안 관점에서 살펴보자. 베이지안 관점을 이용하면 확률을 이용해서 불확실성을 정량화하는 것이 가능하다.&lt;/p&gt;

&lt;p&gt;베이지안 관점을 사용하면 모델 매개변수의 불확실성을 설명할 수 있고 더 나아가 모델 그 자체를 선택하는 데 있어서도 유용하다.&lt;/p&gt;

&lt;p&gt;앞에서 설명한 다항식 곡선 피팅(1.1장) 예시의 매개변수 w에 적용해보자&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫 번째로 데이터를 관측하기 전의 w에 대한 우리의 가정을 사전 확률 분포 p(w)로 표현할 수 있다.&lt;/li&gt;
  &lt;li&gt;관측된 데이터 D = {t1,t2,,,,,tn}은 조건부 확률 p(D|w)로써 작용하게 된다.
이 경우 베이지안 정리는 다음 형태를 띤다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\( p(w \mid D) = \frac{p(D \mid w)p(w)}{p(D)} \) 식(1)&lt;/p&gt;

&lt;p&gt;자세히 설명하면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(p(w \mid D) \): D를 관측한 후의 w에 대한 불확실성을 사후 확률로 표현&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(p(D \mid w) \) : 각각의 다른 매개변수 벡터 w에 대해 관측된 데이터 집합이 얼마나 그렇게 나타날 가능성이 있는지를 표현한 가능도 함수 
           (가능도 함수는 w에 대한 확률 분포가 아니며, 따라서 w에 대해 가능도 함수를 적분하여도 1이 될 필요가 없다)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\( p(w) \): 데이터를 관측하기 전의 w에 대한 우리의 가정, 사전 확률&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\( p(D) \) : 사후 분포가 적합한 확률 분포가 되고 적분값이 1이 되도록 하기 위한 정규화 상수&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;가능도 함수에 대한 정의를 바탕으로 베이지안 정리를 다음처럼 적을 수가 있다.&lt;/p&gt;

&lt;p&gt;사후 확률  ∝ 가능도 x 사전확률 ( 각 값은 전부 w에 대한 함수)&lt;/p&gt;

&lt;p&gt;식(1)의 양쪽 변을 w에 대해 적분하면 베이지안 정리의 분모를 사전확률과 가능도 함수로 표현 가능하다&lt;/p&gt;

&lt;p&gt;\[p(D) = \int p(D \mid \textbf{w})p(\textbf{w})d\textbf{w} \]&lt;/p&gt;

&lt;p&gt;여기서 가능도 함수의 역할을 살펴보면 빈도적 확률 관점과 베이지안 확률 관전에서 다르다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;빈도적 확률 관점 : w가 고정 매개변수로 여겨지며, w의 값은 어떤 형태의 ‘추정값’을 통해서 결정된다. 그리고 추정에서의 오류는
                            가능한 데이터 집합들 D의 분포를 고려함으로써 구할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;베이지안 확률 관점 : 오직 하나의 (실제로 관측될) 데이터 집합 D만 존재하며, 매개변수의 불확실성은 w의 확률 분포를 통해 표현한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;u&gt;빈도적 확률 관점&lt;/u&gt;에서 널리 사용되는 추정값 중 하나는 바로 &lt;b&gt;최대가능도&lt;/b&gt;이다.&lt;/p&gt;

&lt;p&gt;최대가능도를 사용할 경우에 w의 가능도 함수 p(D|w)를 최대화하는 값으로 선택한다.
(머신러닝에서 종종 음의 로그 가능도 함숫값을 오차함수라고 일컫는다. 음의 로그 함수는 단조 감소하는 함수이기 때문에 가능도의 최댓값을 찾는 것이 오차를 최소화하는 것과 동일하다 -&amp;gt; 자세한 내용은 CS229 강의를 정리하면서 설명할 예정이다)&lt;/p&gt;

&lt;p&gt;또한, 빈도적 확률론자들이 오차를 측정하는 방법 중 하나가 부트스트랩이다.
예를 들어 설명하면, 원 데이터 집합이 N개인 데이터 포인트 X = {x1,x2,,,,xn}가 있다고 가정해보자.
X에서 N개의 데이터 포인트를 임의로 복원 추출하여 데이터 집합 Xb를 만든다. 
이 과정을 L번 반복하면 원래 데이터 집합의 표본에 해당하는 크기 N의 데이터 집합을 L개 만들 수 있다.
각각의 부트스트랩 데이터 집합에서의 예측치와 실제 매개변수 값과의 차이를 바탕으로 매개변수 추정값의 통계적 정확도를 판단할 수 있다.&lt;/p&gt;

&lt;p&gt;베이지안 관점의 장점 중 하나는 사전 지식을 추론 과정에서 자연스럽게 포함시킬 수 있다.
동전 10개를 던졌는데 모두 앞면이 나왔다고 가정하자. 빈도적 관점에서는 미래의 모든 동전 던지기에서 앞면만 나올 것이라고 예측한다.대조적으로 베이지안 관점에서는 적당히 합리적인 사전 확률을 사용한다면 이렇게까지 과도한 결론이 나오지 않을 것이다.&lt;/p&gt;

&lt;p&gt;하지만, 베이지안 관점에서는 사전 확률의 선택에 따라 결론이 나오기 때문에 추론 과정에서 주관이 포함될 수밖에 없고 실제로 좋지 않은 사전 분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 높은 확신으로 내놓기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;가우시안-분포&quot;&gt;가우시안 분포&lt;/h4&gt;

&lt;p&gt;이제 가장 중요한 연속 활률 분포 하나를 살펴보고자 한다. 바로 정규 분포라고도 불리는 가우시안 분포이다.&lt;/p&gt;

&lt;p&gt;단일 실수 변수 x에 대해서 가우시안 분포는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ N(x \mid \mu ,\sigma ^{2}) = \frac{1}{\sqrt{2\pi \sigma ^{2}}}exp(-\frac{(x-\mu)^{2}}{2\sigma^{2}}) \]&lt;/p&gt;

&lt;p&gt;위의 식은 두 개의 매개변수 μ(평균),  \(σ^{2} \)(분산)에 의해 통제된다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/2.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/6.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;위의 가우시안 식으로부터 가우시안 분포가 다음의 성질은 만족함을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[N(x \mid \mu ,\sigma ^{2})&amp;gt; 0 \]&lt;/p&gt;

&lt;p&gt;가우시안 분포가 정규화되어 있다는 것 또한 쉽게 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \int_{-\infty }^{\infty}N(x \mid \mu,\sigma^{2})dx = 1 \]&lt;/p&gt;

&lt;p&gt;가우시안 분포를 따르는 임의의 x에 대한 함수의 기댓값을 구할 수 있다. 특히 x의 평균값은 다음과 같다&lt;/p&gt;

&lt;p&gt;\[ E(x) = \int_{-\infty }^{\infty}N(x \mid \mu ,\sigma ^{2}) x dx = \mu \]&lt;/p&gt;

&lt;p&gt;이와 비슷하게 x에 대한 이차 모멘트를 계산해 보자&lt;/p&gt;

&lt;p&gt;\[ E(x^{2}) = \int_{-\infty }^{\infty}N(x \mid \mu ,\sigma ^{2}) x^{2} dx = \mu^{2} +\sigma^{2} \]&lt;/p&gt;

&lt;p&gt;이를 통해 x의 분산을 다음과 같이 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ var(x) = E(x^{2}) - E(x)^{2} = \sigma^{2} \]&lt;/p&gt;

&lt;p&gt;분포의 최댓값을 최빈값(mode)이라 하는데, 가우시안 분포의 경우에는 최빈값과 평균값이 동일하다.&lt;/p&gt;

&lt;p&gt;다음으로는 연속 변수로 이루어진 D차원 벡터 X에 대한 가우시안 분포를 살펴보도록 하자&lt;/p&gt;

&lt;p&gt;\[ N(X \mid \mu,\Sigma ) = \frac{1}{(2\pi) ^{\frac{D}{2}}}\frac{1}{ \mid \Sigma \mid ^{\frac{1}{2}}}exp(-\frac{1}{2}(X-\mu)^{T}\Sigma^{-1}(X-\mu)) \]&lt;/p&gt;

&lt;p&gt;이 식은 가우시안 분포의 가능도 함수에 해당한다.&lt;/p&gt;

&lt;p&gt;관측된 데이터 집합을 바탕으로 확률 분포의 매개변수를 결정하는 표준적인 방법 중 하나는 가능도 함수를 최대화하는 매개변수를 찾는 것이다.&lt;/p&gt;

&lt;p&gt;위의 식에 로그를 취하여 (수학적 분석, 계산을 쉽게하기 위해서 또한 언더플로우 방지) 로그가능도 함수를 다음과 같이 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ lnp(X \mid \mu,\sigma^{2} ) =-\frac{1}{2\sigma^{2}}\sum_{n=1}^{N}(x_{n} - \mu)^{2} - \frac{N}{2}ln\sigma^{2}-\frac{N}{2}ln(2\pi) \]&lt;/p&gt;

&lt;p&gt;μ에 대해 이 식의 최댓값을 찾으면 다음의 최대 가능도해를 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_{n} \]&lt;/p&gt;

&lt;p&gt;이는 바로 관찰된 값{xn}들의 평균인 표본평균이다&lt;/p&gt;

&lt;p&gt;이와 비슷한 방식으로 최댓값을 \(σ^{2} \)에 대해 찾으면 분산에 대한 최대 가능도 해를 다음과 같이 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \sigma^{2}&lt;em&gt;{ML} = \frac{1}{N}\sum&lt;/em&gt;{n=1}^{N}(x_{n}- \mu_{ML})^{2} \]&lt;/p&gt;

&lt;p&gt;이는 표본 평균에 대해 계산된 표본 분산이다(가우시안 분포의 경우, μ,  \( σ^{2} \)에 대한 해가 연관이 없기 때문에 계산 순서를 변경해도 무방하다)&lt;/p&gt;

&lt;p&gt;하지만, 최대가능도 방법에는 한계가 있다
최대가능도 방법이 구조적으로 분포의 분산을 과소평가하게 된다.즉 편향된다.
최대가능도 해인 μ,  \( σ^{2} \)은 데이터 집합 x1,….,xn의 함수다. 각 데이터 집합의 값에 대해 이들의 기댓값을 고려해보자&lt;/p&gt;

&lt;p&gt;\[ E(\mu_{ML}) = \mu \]
\[ E(\sigma^{2}_{ML}) = (\frac{N-1}{N})\sigma^{2} \]&lt;/p&gt;

&lt;p&gt;여기서 분산이 (N-1/N)만큼 과소평가된다.
최대 가능도 방법의 편향 문제는 우리가 앞에서 살펴본 다항식 곡선 피팅에서의 과적합 문제의 근본적인 원인이 된다.
또한, 데이터 포인트의 개수인 N이 커질수록 최대 가능도 해에서의 편향치는 점점 줄어든다&lt;/p&gt;

&lt;p&gt;곡선 피팅에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory(2)/&quot;&gt;1.2. Probability theory (2)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 25, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2 Probability theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory</id>
  <published>2022-02-24T04:01:50+09:00</published>
  <updated>2022-02-24T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;패턴 인식에서 ‘불확실성’은 측정할 때의 노이즈를 통해서도 발생하고 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.
따라서, 확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해 준다.&lt;/p&gt;

&lt;p&gt;예시를 들어보자&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이 예시에서는 X,Y라는 두 가지 확률 변수가 존재한다. X는 \(x_{i} \) (i = 1,….,M)중 아무 값이나 취할 수 있고 Y는 \(y_{j} \) (j = 1,…,L)중 아무 값이나 취할 수 있다. 또한, X와 Y각각에서 표본을 추출하는 시도를 N번 한다고 가정한다.
\(n_{i,j} \)는 \( X = x_{i}, Y = y_{j} \) 인 시도 개수를 의미하며, \(c_{i} \)는 Y 값과는 상관없이 \(X= x_{i} \)인 시도의 숫자, \(r_{j} \)는  X값과 상관없이 \(Y=y_{j} \)인 시도의 숫자를 의미한다.&lt;/p&gt;

&lt;p&gt;\( X = x_{i}, Y = y_{j} \) 일 결합 확률은 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i},Y = y_{i}) = \frac{n_{i,j}}{N} \]&lt;/p&gt;

&lt;p&gt;비슷하게 Y값과 무관하게 X가 \(x_{i} \)값을 가질 확률을 다음과 같다&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) =\frac{c_{i}}{N} \]&lt;/p&gt;

&lt;p&gt;이 두 식을 이용하여 다음을 도출해 낼 수 있다.&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) = \sum_{j=1}^{L}p(X = x_{i},Y = y_{j}) \]&lt;/p&gt;

&lt;p&gt;이것이 확률의 &lt;b&gt;합의 법칙&lt;/b&gt;이다. 여기서 \(P(X = x_{i}) \)는 주변 확률이라 불린다.&lt;/p&gt;

&lt;p&gt;여기서 \(X = x_{i} \)인 사례들만 고려해보자. 그들 중에서 \(Y = y_{i} \)인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 \(p(Y = y_{i} | X = x_{i}) \)로 적을 수 있으며
이를 &lt;b&gt;조건부 확률&lt;/b&gt;이라고 부른다&lt;/p&gt;

&lt;p&gt;\[ p(Y = y_{i} \mid X = x_{i}) = \frac{n_{i,j}}{c_{i}} \]&lt;/p&gt;

&lt;p&gt;지금까지의 식을 이용해서 다음의 관계를 도출할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i} \mid Y = x_{j}) = \frac{n_{i,j}}{c_{i}} = \frac{n_{i,j}}{c_{i}}\cdot \frac{c_{i}}{N} = p(Y = y_{j} \mid X = x_{i})p(X=x_{i}) \]&lt;/p&gt;

&lt;p&gt;이것이 바로 확률의&lt;b&gt; 곱의 법칙&lt;/b&gt;이다&amp;lt;/p&amp;gt;&lt;/p&gt;

&lt;p&gt;이제, 곱의 법칙과 합의 법칙, 대칭성 p(X,Y) = p(Y,X)로 부터 조건부 확률 간의 관계인 다음 식을 도출해 낼 수 있다.
(여기서 부터는 간단하게 확률 변수 X에서 분포를 표현할 때는 p(X)라 적고 특정 값 xi에서의 분포를 표현할 때는 \(p(x_{i}) \)로 적기로 한다)&lt;/p&gt;

&lt;p&gt;\[p(Y \mid X) = \frac{p(X\mid Y)p(Y)}{p(X)} = \frac{p(X\mid Y)p(Y)}{\sum_{Y}p(X\mid Y)p(Y)} \]&lt;/p&gt;

&lt;p&gt;이를 &lt;b&gt;베이즈 정리&lt;/b&gt;라고 한다( 책의 전반에 걸쳐 중요한 역할을 한다)&lt;/p&gt;

&lt;p&gt;여기서 분모는 왼쪽 항을 모든 Y값에 대하여 합했을 때 1이 되도록 하는 역할을 한다.
베이지안 정리는 다음과 같이 해석할 수 있다.
확률 p(A|B)를 알고 있을 때, 관계가 정반대인 확률 p(B|A)를 계산하는 것으로 여기서 P(B)는 사전 확률, p(B|A)는 사후 확률에 해당한다.
여기서, 두 확률 변수가 독립이라면, p(X,Y) = p(X)p(Y) 이다.&lt;/p&gt;

&lt;h4 id=&quot;확률-밀도&quot;&gt;확률 밀도&lt;/h4&gt;

&lt;p&gt;이번에는 연속적인 변수에서의 확률에 대해 알아본다.&lt;/p&gt;

&lt;p&gt;만약 실수 변수 x가 (x,x+δx)구간 안의 값을 가지고 그 변수의 확률이 p(x)δx로 주어진다면, p(x)를 x의 확률 밀도라고 부른다.
이때, x가 (a,b) 구간 사이의 값을 가질 확률은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ p(x \in (a,b)) = \int_{a}^{b}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서, 확률은 양의 값을 가지고 x의 값은 실축선상에 존재해야 하기 때문에 다음의 두 조건을 만족시켜야 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\( p(x) \geq 0 \)&lt;/li&gt;
  &lt;li&gt;\( \int_{-\infty }^{\infty}p(x)dx = 1 \)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;누적-분포-함수&quot;&gt;누적 분포 함수&lt;/h4&gt;

&lt;p&gt;x가 (-∞,z) 범위에 속할 확률은 &lt;b&gt;누적 분포 함수 &lt;/b&gt; 로 표현된다.&lt;/p&gt;

&lt;p&gt;\[ P(z) = \int_{-\infty }^{z}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서 P’(x) = p(x)이다.&lt;/p&gt;

&lt;p&gt;만약 x가 이산 변수일 경우 p(x)를  &lt;b&gt; 확률 질량 함수 &lt;/b&gt;라고 부르기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;기댓값&quot;&gt;기댓값&lt;/h4&gt;
&lt;p&gt;기댓값은 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값을 의미한다. 이산 분포의 경우 기댓값은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(f) = \sum_{x}p(x)f(x) \]&lt;/p&gt;

&lt;p&gt;여기서 p(x)는 각 x값에 해당하는 확률이며 이것을 가중치로 사용한 가중 평균을 구하는 것으로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;연속 변수의 경우에는 해당 확률 밀도에 대해 적분을 시행해서 기댓값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(f) = \int p(x)f(x)dx \]&lt;/p&gt;

&lt;p&gt;공분산에 해당하는 특징은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E[aX + b] = aE[X] + b&lt;/li&gt;
  &lt;li&gt;E[X + Y] = E[X] + E[Y]&lt;/li&gt;
  &lt;li&gt;E[XY] = E[X]E[Y]&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;공분산&quot;&gt;공분산&lt;/h4&gt;

&lt;p&gt;공분산을 설명하기 앞서 분산부터 설명하면, f(x)의 분산은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ var(f) = E((f(x) - E(f(x)))^{2}) \]&lt;/p&gt;

&lt;p&gt;이는 f(x)가 평균값 E[f(x)]로부터 전반적으로 얼마나 멀리 분포되었는지를 나타내는 값이다.&lt;/p&gt;

&lt;p&gt;이를 전개하여 정리하면 다음과 같다. (식의 이해를 돕기 위하여 상수인 E[f(x)] 부분을  μ라 표현)&lt;/p&gt;

&lt;p&gt;\( var(f) = E(f(x)^{2} -2\mu f(x) +\mu^{2})) \)  -&amp;gt; 공분산 특징 첫 번째 이용&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) -2\mu E(f(x)) +\mu^{2} \)&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) - E(f(x))^{2} \)&lt;/p&gt;

&lt;p&gt;여기서 변수 x 그 자체에도 고려가능하다.&lt;/p&gt;

&lt;p&gt;다음으로 두 개의 확률 변수 x 와 y에 대해서 공분산은 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ cov(x,y) = E((x - E(x))(y - E(y)) \]
\[= E(xy) - E(x)E(y) \]&lt;/p&gt;

&lt;p&gt;이는 x값과 y값이 얼마나 함께 같이 변동하는가에 대한 지표이며 만얀 x,y가 서로 독립적일 경우 공부산값은 0으로 간다.&lt;/p&gt;

&lt;p&gt;베이지안 확률에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory/&quot;&gt;1.2 Probability theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 24, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[ LECTURE 01]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/CS229-LECTURE-01/" />
  <id>http://localhost:4000/articles/[CS229]LECTURE 01</id>
  <published>2022-02-23T07:50:50+09:00</published>
  <updated>2022-02-23T07:50:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/CS229-LECTURE-01/&quot;&gt; LECTURE 01&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 23, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[베타 분포]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/blog/%E1%84%87%E1%85%A6%E1%84%90%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/" />
  <id>http://localhost:4000/blog/베타 분포</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/blog/%E1%84%87%E1%85%A6%E1%84%90%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/&quot;&gt;베타 분포&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[감마 분포]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/blog/%E1%84%80%E1%85%A1%E1%86%B7%E1%84%86%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/" />
  <id>http://localhost:4000/blog/감마 분포</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/blog/%E1%84%80%E1%85%A1%E1%86%B7%E1%84%86%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/&quot;&gt;감마 분포&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.1 Polynomial Curve Fitting]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.1-Polynomial-Curve-Fitting/" />
  <id>http://localhost:4000/articles/[PRML]1.1 Polynomial Curve Fitting</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/2.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/2.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/3.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/3.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/4.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/4.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.1-Polynomial-Curve-Fitting/&quot;&gt;1.1 Polynomial Curve Fitting&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>

</feed>