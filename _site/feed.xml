<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">MinPy</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://localhost:4000" />
<updated>2022-03-22T10:25:48+09:00</updated>
<id>http://localhost:4000/</id>
<author>
  <name>Cho min Hee</name>
  <uri>http://localhost:4000/</uri>
  <email>aezjk56@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[2.1 Binary Variables]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-2.1-Binary-Variables/" />
  <id>http://localhost:4000/articles/[PRML]2.1 Binary Variables</id>
  <published>2022-03-02T04:01:50+09:00</published>
  <updated>2022-03-02T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;이 장에서 논의할 분포의 역할들 중 하나는 한정된 수의 관찰 집합 x1,….,xn이 주어졌을 때 확률 변수 x의 확률 분포 p(x)를 모델링하는 것이다. 이를 &lt;b&gt;밀도 추정 문제 &lt;/b&gt; 라고 한다.
이 장의 목표를 위해서 데이터 포인트들은 독립적이며, 동일하게 분포되어 있다고 가정할 것이다.&lt;/p&gt;

&lt;p&gt;우선, 이산 확률 변수의 이항 분포와 다항 분포를 살펴보고 그 다음으로 연속 확률 변수의 가우시안 분포에 대해 논의할 것이다. 이 분포들은 매개변수 분포의 예다. 
이러한 모델을 밀도 추정 문제에 적용하기 위해서는 관찰된 데이터 집합을 바탕으로 적절한 매개변숫값을 구하는 과정이 필요하다.&lt;br /&gt;
두 가지 관점에서 살펴보자&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;빈도적 관점 : 어떤 특정 기준을 최적화하는 방법으로 매개변수를 찾는다. 최적화 기준의 예로 가능도 함수가 있다.&lt;/li&gt;
  &lt;li&gt;베이지안 관점 : 매개변수에 대한 사전 분포를 바탕으로 관측된 데이터 집합이 주어졌을 때의 해당 사후분포를 계산한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;켤레 사전 확률이 중요한 역할을 한다는 것도 살펴볼 것이다. 켤레 사전 확률은 사후 확률이 사전 확률과 같은 함수적 형태를 띠도록 만들어준다. 그 결과 , 베이지안 분석이 매우 단순해진다.&lt;/p&gt;

&lt;p&gt;매개변수적인 접근법의 한계점도 존재한다. 분포가 특정한 함수 형태를 띠고있다고 가정하지만 몇몇 적용 사례의 경우에는 이 가정이 적절하지 않다. 이런 경우, 비매개변수적 밀도 추정 방식을 대안으로 활용할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;이산-확률-변수&quot;&gt;이산 확률 변수&lt;/h4&gt;

&lt;p&gt;하나의 이진 확률 변수 \( x \in (0,1) \)을 고려해 보자. 0과 1이 나올 확률이 동일하지 않다고 가정하면 이때 x = 1일 확률은 매개변수 \( \mu \)를 통해 다음과 같이 표현할 수 있다.
\[ p(x = 1 \mid \mu) = \mu (0 \leq \mu \leq 1)\]
\[ p(x = 0 \mid \mu ) = 1 - \mu \]&lt;/p&gt;

&lt;p&gt;따라서 x에 대한 확률은 다음의 형태로 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ Bern(x \mid \mu ) = \mu^{x}(1 - \mu)^{1-x} \]&lt;/p&gt;

&lt;p&gt;이것을 &lt;b&gt; 베르누이 분포 &lt;/b&gt;라고 한다. 베르누이 분포는 정규화되어 있으며, 그 평균과 분산이 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(x) = \mu \]
\[ var(x) = \mu(1-\mu) \]&lt;/p&gt;

&lt;p&gt;x의 관극값이 데이터 집합 \( D = (x_{1},…..x_{N})\)이 주어졌다고 하자. 관측값들이 \( p(x \mid \mu)\)에서 독립적으로 추출되었다는 가정하에 \( \mu \)함수로써 가능도 함수를 구성할 수 있다.
\[ p(D \mid \mu ) = \prod_{n=1}^{N}p(x_{n} | \mu) = \prod_{n=1}^{N}\mu^{x_{n}}(1-\mu)^{1 - x_{n}} \]&lt;/p&gt;

&lt;p&gt;빈도적 관점에서는 가능도 함수를 최대화하는 \( \mu \)를 찾아서 \( \mu \)값을 추정할 수 있다. 베르누이 분포의 경우 로그 가능도 함수는 다음으로 주어진다.&lt;/p&gt;

&lt;p&gt;\[ lnp(D \mid \mu ) = \sum_{n=1}^{N}lnp(x_{n} \mid \mu) = \sum_{n=1}^{N}(x_{n}ln\mu + (1-x_{n})ln(1-\mu)) \]&lt;/p&gt;

&lt;p&gt;로그 가능도함수는 오직 관측값들의 합인 \(\sum_{n}x_{n}\)을 통해서만 N개의 관측값 \(x_{n} \)과 연관된다는 점에 주목할 필요가 있다. 이 합은 &lt;b&gt; 충분 통계량 &lt;/b&gt;의 예시 중 하나다.&lt;/p&gt;

&lt;p&gt;\( lnp(D \mid \mu )\)을 \(\mu \)에 대해 미분하고 이를 0과 같다고 놓으면 다음과 같은 최대 가능도 추정값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_{n}\]&lt;/p&gt;

&lt;p&gt;이는 &lt;b&gt; 표본 평균 &lt;/b&gt;이라고도 불린다. 데이터에서 x = 1인 관찰값의 수를 m이라고 하면 다음의 형태로 다시 적을 수 있다. 
\[ \mu_{ML} = \frac{m}{N} \]&lt;/p&gt;

&lt;p&gt;즉, 최대가능도 체계하에에서 동전으로 예시를 들면, 동전의 앞면이 나올 확률은 데이터 집합에서 앞면이 나온 비율로 주어지게 되는 것이다.&lt;/p&gt;

&lt;p&gt;하지만 최대가능도를 사용할 경우 과적합이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;동전을 세 번 던졌는데 세 번 다 앞면이 나온 경우를 생각해보자. 그러면 N = m = 3이고 따라서 \( \mu_{ML} = 1 \)이 된다( 이 경우 앞으로 던지는 모든 동전이 앞면으로 나올 것이라고 예측하는 것이다! ) 이것이 실제로 최대 가능도를 사용했을 경우 발생할 수 있는 극단적인 사례다.( 이후에 사전 분포를 바탕으로 나은 결과를 도출할 수 있다.)&lt;/p&gt;

&lt;p&gt;크기 N의 데이터가 주어졌을 때 x = 1인 관측값의 수 m에 대해서도 분포를 생각할 수 있다. 이를 &lt;b&gt; 이항 분포 &lt;/b&gt;라 한다. 위에서 구한 가능도 함수로부터 이항 분포는 \( \mu^{m}(1 - \mu)^{N - M}\)에 비례한다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;정규화 계수를 구하기 위해서 동전 던지기로 예시를 들면, 동전 던지기를 N번 했을 때 앞면이 m번 나올 수 있는 가능한 모든 가짓수를 구해야 한다. 따라서 이항 분포를 다음과 같이 적을 수 있다.
\[Bin(m \mid N,\mu) = \binom{N}{m}\mu^{m}(1-\mu)^{N-m} \]&lt;/p&gt;

&lt;p&gt;여기서 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ \binom{N}{m} \equiv \frac{N!}{(N-m)!m!} \]&lt;/p&gt;

&lt;p&gt;\( \binom{N}{m} \)은 N개의 물체들 중 m개의 물체를 선별하는 가짓수를 구한 것이다. 이해를 위해 N = 10이고 \(\mu \)= 0.25일 때의 이항 분포의 히스토그램은 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/8.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/8.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;베타-분포&quot;&gt;베타 분포&lt;/h4&gt;

&lt;p&gt;이미 살펴본 방법들은 데이터 수가 적을 때 심각한 과적합이 일어나기 쉽다(동전 던지기 예시를 생각해보자!)&lt;/p&gt;

&lt;p&gt;이 문제에 베이지안적으로 접근하기 위해서는 매개변수 \( \mu \)에 대한 사전 분포 \( p(\mu) \)를 도입하는 것이 필요하다.&lt;/p&gt;

&lt;p&gt;가능도 함수가 \( \mu^{x}(1-x)^{1-x}\)의 형태를 가지는 인자들의 곱의 형태를 띠고 있다는 것에 주목해보면, 만약 \(\mu \)dhk \( (1 - \mu) \)의 거듭제곱에 비례하는 형태를 사전 분포에 선택한다면, 사전 확률과 가능도 함수의 곱에 비례하는 사후 분포 역시 사전 분포와 같은 함수적 형태를 가지게 될 것이다. 이러한 성질을 &lt;b&gt; 켤레성&lt;/b&gt;이라고 한다. ( 켤레성에 대한 이해를 돕고자 켤레의 수학적 의미를 설명하면, 두 개의 점,선,도형,수 등이 서로 대칭이거나 보완적인 관계에 있는 경우 켤레라고 한다.)&lt;/p&gt;

&lt;p&gt;지금까지의 논의를 바탕삼아 사전 분포로 베타 분포를 사용할 것이다.( &lt;a href=&quot;https://jjomaeng.github.io/blog/베타-분포/&quot;&gt;왜 베타 분포를 사용하는 지에 대한 자세한 설명은 여기에 작성하였습니다!&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;베타 분포는 다음의 형태를 가진다.
\[ Beta(\mu \mid a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\]&lt;/p&gt;

&lt;p&gt;\( \Gamma(x) \)는 다음과 같이 정의된다. (&lt;a href=&quot;https://jjomaeng.github.io/blog/감마-분포/&quot;&gt;감마 함수에 대한 자세한 내용은 여기에 작성하였습니다!&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;\[ \Gamma(x) = \int_{0}^{\infty } u^{x-1} e^{-1} du \]&lt;/p&gt;

&lt;p&gt;베타 분포의 계수들은 베타 분포가 정규화되도록 한다.&lt;/p&gt;

&lt;p&gt;\[ \int_{0}^{1}Beta(\mu \mid a,b) d\mu = 1 \]&lt;/p&gt;

&lt;p&gt;베타 분포의 평균과 분산은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(\mu) = \frac{a}{a+b} \]
\[ var(\mu) = \frac{ab}{(a+b)^{2}(a+b+1)} \]&lt;/p&gt;

&lt;p&gt;매개변수 a와 b는 이들이 매개변수 \( \mu \)의 분포를 조절하기 때문에 &lt;b&gt;초매개변수&lt;/b&gt;라고 불린다.&lt;/p&gt;

&lt;p&gt;이제 베타 사전 분포와 이항 가능도 함수를 곱한 후 정규화를 시행함으로써 \( \mu \)의 사후 분포를 구할 수 있다.
\( \mu \)와 관련되어 있는 인자들만 남기면 사후 분포가 다음의 형태를 가지게 되는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(\mu \mid m,l,a,b) \propto \mu^{m+a-1}(1 - /m)^{l+b-1}\]&lt;/p&gt;

&lt;p&gt;여기서 l = N -m이며 동전 던기기 예시에서 ‘뒷면’의 개수에 해당한다.&lt;/p&gt;

&lt;p&gt;사후 분포의 식은 사전 분포와 \(\mu \)에 대해서 같은 함수적 종속성을 가지고 있다는 것을 확인할 수 있다. 이 사실이 가능도 함수에 대해서 사전 분포가 켤레성을 가지고 있다는 것을 반영한다. 
실제로 사후 분포는 또 다른 베타 분포일 뿐이다.
그러면 사후 분포의 정규화 계수는 베타 분포의 식을 참고하여 구할 수 있다. 그 결과 다음을 얻게 된다.&lt;/p&gt;

&lt;p&gt;\[ p(\mu \mid m,l,a,b) = \frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)} \mu^{m+a-1}(1-\mu)^{l+b-1}\]&lt;/p&gt;

&lt;p&gt;x = 1인 값이(예를 들어 앞면의 수) m개 있고 x = 0인 값 ㅣ개가 있는 데이터 집합을 관찰한 결과, 사전 분포와 비교했을 떄 사후 분포에서는 a의 값이 m만큼, b의 값이 l만큼 증가하는 것을 확인할 수 있다.
이 사실로부터 사전 분포의 초매개변수 a와b를 각각 x = 1, x = 0인 경우에 대한 &lt;b&gt;유효 관찰수&lt;/b&gt;로 해석할 수 있다.(a와 b는 반드시 정수가 아니어도 된다.)&lt;/p&gt;

&lt;p&gt;만약 우리가 추가적으로 관측 데이터를 얻게 되면 지금의 사후 분포가 새로운 사전 분포가 될 수 있다. 
매번 업데이트 단계에서 새로운 관측값에 해당하는 가능도 함수를 곱하고 그 다음에 정규화를 시행해서 새로운 수정된 사후 분포를 &lt;b&gt;순차적&lt;/b&gt;으로 얻는 것이다.
각 단계에서 사후 분포는 x = 1과 x = 0에 해당하는 관측값들의 전체 숫자가 새로운 a와 b값으로 주어지는 베타 분포에 해당한다. x = 1인 새로운 관측값이 주어졌을 때는 단순히 a값을 1 증가시키고 x = 0인 관측값이 새로 주어졌을 때는 b값을 1 증가시키면 된다.
이 과정의 한 단계를 그림으로 보면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/10.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/10.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이는 사전 분포나 가능도 함수의 선택과는 상관없이 오직 데이터가 독립적이고 동이랗게 분포되었다는 것에만 의존적이다.
순차적인 방법론은 관측값을 한 번에 하나씩, 혹은 한 번에 적은 수 만큼 사용한다.
사용한 관측값들을 다음 관측값을 사용하기 전에 버린다. 
이는 실시간 학습에 적용할 수 있으며, 큰 데이터 집합에도 사용 가능하다.&lt;/p&gt;

&lt;p&gt;만약 우리의 목표가 다음 시도의 결과값을 가장 잘 예측하는 것이라면, 관측 데이터 집합 D가 주어진 상황하에서 x의 예측 분포를 계산해야 한다.
확률의 합과 곱의 법칙에 따라서 이는 다음 형태를 띤다.&lt;/p&gt;

&lt;p&gt;\[ p(x = 1 \mid D) = \int_{0}^{1}p(x=1 \mid \mu)p(\mu \mid D)d\mu = \int_{0}^{1}\mu p(\mu \mid D )d\mu = E(\mu \mid D)\]&lt;/p&gt;

&lt;p&gt;사후 분포 \(p(\mu \mid D)\)에 대한 결과 식과 베타 분포의 평균에 대한 식을 이용해서 다음을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(x = 1 \mid D) = \frac{m+a}{m_a+l+b}\]&lt;/p&gt;

&lt;p&gt;전체 관측값(실제 관측값과 허구의 사전 관측값 둘 다)중에서 x = 1인 관측값의 비율로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;데이터 집합이 무한이 커서 \( m,l \rightarrow  \infty \)이 된다면 최대가능도의 결과값과 같아진다.
(베이지안 결과값과 최대 가능도의 결과값이 무한하게 큰 데이터 집합 하에서 동일한 것은 매우 일반적인 성향이다.)&lt;/p&gt;

&lt;p&gt;제한된 크기의 데이터 집합에서 \(\mu \)의 사후 평균 값은 사전 평균값과 사건의 상대적 빈도수를 바탕으로 한 가능도 추정치 사이에 있게 된다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/9.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/9.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;위의 그림에서 관측값의 수가 늘어날수록 사후 분포가 더 날카롭고 뾰족해는 것을 확인할 수 있다. 이는 베타 분포의 분산에 대한 식의 결과에도 확인할 수 있다.
\( a \rightarrow  \infty \), 또는 \( b \rightarrow  \infty \)가 됨에 따라서 분산이 0에 가까워지는 것이다.&lt;/p&gt;

&lt;p&gt;더 많은 데이터를 관측할수록 사후 분포의 확실성의 정도가 꾸준히 감소하는 것은 평균적으로 베이지안 학습의 일반적인 성질이다.&lt;/p&gt;

&lt;p&gt;이를 확인하기 위해 베이지안 학습을 빈도적 관점에서 살펴보도록 하자.&lt;/p&gt;

&lt;p&gt;관측된 데이터 집합 D에 대해서 매개변수 \( \theta \)를 추정하는 일반적인 베이지안 추론 문제를 고려해 보자. 이 문제는 결합 분포 \( p(\theta ,D)\)로 표현 가능하다. 매개변수 \( \theta \)에 대한 기댓값은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ E_{\theta}(\theta) = E_{D}(E_{\theta} \mid D)\]
\[E_{\theta}(\theta) \equiv \int p(\theta)\theta d\theta \]
\[E_{D}(E_{\theta}(\theta \mid D)) \equiv \int(\int \theta p(\theta \mid D)d\theta)p(D)dD \]&lt;/p&gt;

&lt;p&gt;이로부터 데이터가 생성된 원 분포에 대해 평균을 낸 \( \theta \)의 사후 평균값은 \( \theta \)의 사전 평균과 같다는 것을 알 수 있다. 이와 유사하게 다음도 증명할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ var_{\theta }(\theta ) = E_{D}(var_{\theta}( \theta \mid D)) + var_{D}(E_{\theta}( \theta \mid D))\]&lt;/p&gt;

&lt;p&gt;위의 식의 왼쪽 변은 \(\theta \)의 사전 분산에 해당한다. 오른쪽 변의 첫 번째 항은 \(\theta \)의 사후 분산의 평균이며, 두 번째 항은 \(\theta \)의 사후 평균의 분산에 해당한다.
이 분산은 양의 값을 가진다. 따라서 이 결과에 따르면 평균적으로 \(\theta \)의 사후 분산은 사전 분산보다 작다는 것을 알 수 있다. 이 분산값의 감소치는 사후 평균의 분산값이 클수록 더 크게 된다.
(이러한 추세는 평균적으로만 옳으며 , 특정 관찰 집합에 대해서는 사후 분산이 사전 분산보다 클수도 있다.)&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-2.1-Binary-Variables/&quot;&gt;2.1 Binary Variables&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on March 02, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.6 Information Theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.6-Information-Theory/" />
  <id>http://localhost:4000/articles/[PRML]1.6 Information Theory</id>
  <published>2022-03-01T04:01:50+09:00</published>
  <updated>2022-03-01T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.6-Information-Theory/&quot;&gt;1.6 Information Theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on March 01, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.5 Decision Theory(2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.5-Decision-Theory(2)/" />
  <id>http://localhost:4000/articles/[PRML]1.5 Decision Theory(2)</id>
  <published>2022-02-28T04:01:50+09:00</published>
  <updated>2022-02-28T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;패턴 인식에서 ‘불확실성’은 측정할 때의 노이즈를 통해서도 발생하고 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.
따라서, 확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해 준다.&lt;/p&gt;

&lt;p&gt;예시를 들어보자&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이 예시에서는 X,Y라는 두 가지 확률 변수가 존재한다. X는 \(x_{i} \) (i = 1,….,M)중 아무 값이나 취할 수 있고 Y는 \(y_{j} \) (j = 1,…,L)중 아무 값이나 취할 수 있다. 또한, X와 Y각각에서 표본을 추출하는 시도를 N번 한다고 가정한다.
\(n_{i,j} \)는 \( X = x_{i}, Y = y_{j} \) 인 시도 개수를 의미하며, \(c_{i} \)는 Y 값과는 상관없이 \(X= x_{i} \)인 시도의 숫자, \(r_{j} \)는  X값과 상관없이 \(Y=y_{j} \)인 시도의 숫자를 의미한다.&lt;/p&gt;

&lt;p&gt;\( X = x_{i}, Y = y_{j} \) 일 결합 확률은 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i},Y = y_{i}) = \frac{n_{i,j}}{N} \]&lt;/p&gt;

&lt;p&gt;비슷하게 Y값과 무관하게 X가 \(x_{i} \)값을 가질 확률을 다음과 같다&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) =\frac{c_{i}}{N} \]&lt;/p&gt;

&lt;p&gt;이 두 식을 이용하여 다음을 도출해 낼 수 있다.&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) = \sum_{j=1}^{L}p(X = x_{i},Y = y_{j}) \]&lt;/p&gt;

&lt;p&gt;이것이 확률의 &lt;b&gt;합의 법칙&lt;/b&gt;이다. 여기서 \(P(X = x_{i}) \)는 주변 확률이라 불린다.&lt;/p&gt;

&lt;p&gt;여기서 \(X = x_{i} \)인 사례들만 고려해보자. 그들 중에서 \(Y = y_{i} \)인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 \(p(Y = y_{i} | X = x_{i}) \)로 적을 수 있으며
이를 &lt;b&gt;조건부 확률&lt;/b&gt;이라고 부른다&lt;/p&gt;

&lt;p&gt;\[ p(Y = y_{i} \mid X = x_{i}) = \frac{n_{i,j}}{c_{i}} \]&lt;/p&gt;

&lt;p&gt;지금까지의 식을 이용해서 다음의 관계를 도출할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i} \mid Y = x_{j}) = \frac{n_{i,j}}{c_{i}} = \frac{n_{i,j}}{c_{i}}\cdot \frac{c_{i}}{N} = p(Y = y_{j} \mid X = x_{i})p(X=x_{i}) \]&lt;/p&gt;

&lt;p&gt;이것이 바로 확률의&lt;b&gt; 곱의 법칙&lt;/b&gt;이다&amp;lt;/p&amp;gt;&lt;/p&gt;

&lt;p&gt;이제, 곱의 법칙과 합의 법칙, 대칭성 p(X,Y) = p(Y,X)로 부터 조건부 확률 간의 관계인 다음 식을 도출해 낼 수 있다.
(여기서 부터는 간단하게 확률 변수 X에서 분포를 표현할 때는 p(X)라 적고 특정 값 xi에서의 분포를 표현할 때는 \(p(x_{i}) \)로 적기로 한다)&lt;/p&gt;

&lt;p&gt;\[p(Y \mid X) = \frac{p(X\mid Y)p(Y)}{p(X)} = \frac{p(X\mid Y)p(Y)}{\sum_{Y}p(X\mid Y)p(Y)} \]&lt;/p&gt;

&lt;p&gt;이를 &lt;b&gt;베이즈 정리&lt;/b&gt;라고 한다( 책의 전반에 걸쳐 중요한 역할을 한다)&lt;/p&gt;

&lt;p&gt;여기서 분모는 왼쪽 항을 모든 Y값에 대하여 합했을 때 1이 되도록 하는 역할을 한다.
베이지안 정리는 다음과 같이 해석할 수 있다.
확률 p(A|B)를 알고 있을 때, 관계가 정반대인 확률 p(B|A)를 계산하는 것으로 여기서 P(B)는 사전 확률, p(B|A)는 사후 확률에 해당한다.
여기서, 두 확률 변수가 독립이라면, p(X,Y) = p(X)p(Y) 이다.&lt;/p&gt;

&lt;h4 id=&quot;확률-밀도&quot;&gt;확률 밀도&lt;/h4&gt;

&lt;p&gt;이번에는 연속적인 변수에서의 확률에 대해 알아본다.&lt;/p&gt;

&lt;p&gt;만약 실수 변수 x가 (x,x+δx)구간 안의 값을 가지고 그 변수의 확률이 p(x)δx로 주어진다면, p(x)를 x의 확률 밀도라고 부른다.
이때, x가 (a,b) 구간 사이의 값을 가질 확률은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ p(x \in (a,b)) = \int_{a}^{b}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서, 확률은 양의 값을 가지고 x의 값은 실축선상에 존재해야 하기 때문에 다음의 두 조건을 만족시켜야 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\( p(x) \geq 0 \)&lt;/li&gt;
  &lt;li&gt;\( \int_{-\infty }^{\infty}p(x)dx = 1 \)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;누적-분포-함수&quot;&gt;누적 분포 함수&lt;/h4&gt;

&lt;p&gt;x가 (-∞,z) 범위에 속할 확률은 &lt;b&gt;누적 분포 함수 &lt;/b&gt; 로 표현된다.&lt;/p&gt;

&lt;p&gt;\[ P(z) = \int_{-\infty }^{z}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서 P’(x) = p(x)이다.&lt;/p&gt;

&lt;p&gt;만약 x가 이산 변수일 경우 p(x)를  &lt;b&gt; 확률 질량 함수 &lt;/b&gt;라고 부르기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;기댓값&quot;&gt;기댓값&lt;/h4&gt;
&lt;p&gt;기댓값은 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값을 의미한다. 이산 분포의 경우 기댓값은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(f) = \sum_{x}p(x)f(x) \]&lt;/p&gt;

&lt;p&gt;여기서 p(x)는 각 x값에 해당하는 확률이며 이것을 가중치로 사용한 가중 평균을 구하는 것으로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;연속 변수의 경우에는 해당 확률 밀도에 대해 적분을 시행해서 기댓값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(f) = \int p(x)f(x)dx \]&lt;/p&gt;

&lt;p&gt;공분산에 해당하는 특징은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E[aX + b] = aE[X] + b&lt;/li&gt;
  &lt;li&gt;E[X + Y] = E[X] + E[Y]&lt;/li&gt;
  &lt;li&gt;E[XY] = E[X]E[Y]&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;공분산&quot;&gt;공분산&lt;/h4&gt;

&lt;p&gt;공분산을 설명하기 앞서 분산부터 설명하면, f(x)의 분산은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ var(f) = E((f(x) - E(f(x)))^{2}) \]&lt;/p&gt;

&lt;p&gt;이는 f(x)가 평균값 E[f(x)]로부터 전반적으로 얼마나 멀리 분포되었는지를 나타내는 값이다.&lt;/p&gt;

&lt;p&gt;이를 전개하여 정리하면 다음과 같다. (식의 이해를 돕기 위하여 상수인 E[f(x)] 부분을  μ라 표현)&lt;/p&gt;

&lt;p&gt;\( var(f) = E(f(x)^{2} -2\mu f(x) +\mu^{2})) \)  -&amp;gt; 공분산 특징 첫 번째 이용&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) -2\mu E(f(x)) +\mu^{2} \)&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) - E(f(x))^{2} \)&lt;/p&gt;

&lt;p&gt;여기서 변수 x 그 자체에도 고려가능하다.&lt;/p&gt;

&lt;p&gt;다음으로 두 개의 확률 변수 x 와 y에 대해서 공분산은 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ cov(x,y) = E((x - E(x))(y - E(y)) \]
\[= E(xy) - E(x)E(y) \]&lt;/p&gt;

&lt;p&gt;이는 x값과 y값이 얼마나 함께 같이 변동하는가에 대한 지표이며 만얀 x,y가 서로 독립적일 경우 공부산값은 0으로 간다.&lt;/p&gt;

&lt;p&gt;베이지안 확률에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.5-Decision-Theory(2)/&quot;&gt;1.5 Decision Theory(2)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 28, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.5 Decision Theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.5-Decision-Theory/" />
  <id>http://localhost:4000/articles/[PRML]1.5 Decision Theory</id>
  <published>2022-02-27T04:01:50+09:00</published>
  <updated>2022-02-27T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;패턴 인식 문제를 풀 때는 불확실성이 존재하는 상황에서 의사 결정을 내려야 하는 경우가 많다. 이런 상황에서 결정 이론과 확률론을 함께 사용하면 최적의 의사 결정을 내릴 수 있다.&lt;/p&gt;

&lt;p&gt;입력 벡터 X와 타깃 변수 벡터 t가 존재하는 상황에서 새로운 입력 변수 X가 주어졌을 때 해당 타깃 변수 벡터 t를 예측하는 문제에 대해서 생각해보자. 결합 확률 분포 p(x,t) 는 이 변수들의 전체 불확실성을 요약해서 나타낸다. 주어진 훈련 집합 데이터에서 p(x.t)를 찾아내는 것은 추론문제의 대표적인 예시다. 실제 응용 사례에서는 대부분의 경우 t에 대해서 예측하는 것이 더 중요한 문제이다. t가 어떤 값을 가질 것 같은지를 바탕으로 특정 행동을 취해야 할 수도 있다. 이를 위한 이론적 토대가 바로 결정 이론이다.&lt;/p&gt;

&lt;p&gt;일반적인 추론 문제는 결합 확률 분포를 결정하는 과정을 포함하고 있다. 결합 확률 분포는 매우 유용한 값이긴 하지만 최종적으로 우리가 하고 싶은 것은 우리가 어떤 행동을 취해야 할 지 결정하는 것이다. 또한, 해당 결정이 최적이기를 바라는데 이것이 바로 결정단계이다. 결정 이론이 하려는 것은 적절한 확률들이 주어진 상태에서 어떻게 하면 최적의 결정을 내릴 수 있는 가를 설명하는 것이다.&lt;/p&gt;

&lt;p&gt;더 자세한 분석을 하기에 앞서, 의사 결정에 있어서 확률이 어떤 역할을 하는지 간략하게 살펴보자. 우리의 목표는 새 데이터 X를 구한 후에 두 개의 클래스 중 어떤 것으로 분류해보는 것이라고 하자. 우리는 데이터가 주어졌을 때 각각의 클래스의 조건부 확률을 알아내고 싶으며 이는 \( p(C_{k}\mid x) \)로 표현된다. 베이지안 정리를 사용하면 이 확률들을 다음과 같은 형태로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(C_{k} \mid \textbf{x}) = \frac{p(\textbf{x} \mid C_{k})p(C_{k})}{p(\textbf{x})}\]&lt;/p&gt;

&lt;p&gt;위의 베이지안 정리에서 사용된 모든 값들은 결합 확률 분포 \( p(\textbf{x} \mid C_{k}) \)를 활용하여 구할 수 있다. \( p(C_{k}) \)는 클래스 \( C_{k} \)에 포함될 사전 확률, \( p(C_{k} \mid \textbf{x}) \)는 사후 확률에 해당한다. 만약 우리의 목표가 X를 잘못된 클래스에 포함시킬 가능성을 최소화하는 것이라면, 직관적으로 우리는 더 높은 사후 확률을 가진 클래스를 고르게 될 것이다.&lt;/p&gt;

&lt;h4 id=&quot;오분류-비율의-최소화&quot;&gt;오분류 비율의 최소화&lt;/h4&gt;

&lt;p&gt;우리는 목표가 단순히 잘못된 분류 결과의 숫자를 가능한 한 줄이는 것이라고 해보자. 이를 위해서는 각각의 x를 가능한 클래스들 중 하나에 포함시키는 규칙이 필요하다. 이 규칙은 입력 공간을 결정 구역이라고 불리는 구역 \(R_{k} \)들로 나누게 될 것이다. \( R_{k} \)는 클래스의 수만큼 존재할 것이고 Rk에 존재하는 모든 포인트들은 클래스 \( C_{k} \)에 포함될 것이다. 결정 구역들 사이의 경계를 결정 경계 혹은 결정 표면이라고 부른다.
최적의 결정 규칙을 찾아내기 위해서 두 개의 클래스를 가진 경우를 생각해보자. \( C_{1} \)에 속한 변수 x가 \(C_{2} \)에 포함되는 경우나 그 반대의 경우에 ‘실수’가 발생한다. 실수가 발생할 확률은 다음의 식으로 주어진다.&lt;/p&gt;

&lt;p&gt;\[ p(mistake) = p(x \in R_{1},C_{2}) + p( x \in R_{2},R_{1}) = \int_{R_{1}}p(x,C_{2}) + \int_{R_{2}}p(x,C_{1})dx\]&lt;/p&gt;

&lt;p&gt;p(mistake)를 최소화하기 위해서는 각각의 X를 피적분 함수들 중 더 작은 값을 가진 클래스에 포함시켜야 한다.
따라서 \( p(x,C_{1}) &amp;gt; p(x,C_{2}) \)인 경우에는 x를 C1에 포함시켜야 한다. 확률의 곱 법칙에 따라서 \( p(x,C_{k}) = p(C_{k} \mid x)p(x) \)다. p(x)는 양쪽의 항에서 동일하다. 따라서 p(mistake)를 최소화하기 위해서는 각각의 X를 사후 확률 \(p(C_{k} \mid x) \)가 최대가 되는 클래스에 포함시키면 된다는 결론을 낼 수 있다. 하나의 입력 변수 x와 두 클래스의 경우에 대한 해당 도식은 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/16.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/16.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;다른 관점에서 K개의 클래스를 가진 경우에는 올바르게 분류된 경우의 확률을 극대화할 수 있으며 이 방법이 더 일반적이고 조금 더 쉽다.&lt;/p&gt;

&lt;p&gt;\[ p(correct) = \sum_{k=1}^{K}p(x \in R_{k},C_{k}) = \sum_{k=1}^{K}\int_{R_{k}}p(\textbf{x},C_{k})dx \]&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;각각의 x가 p(x,Ck)가 최대인 클래스로 분류되도록 Rk를 선택할 경우에 위의 식 값이 최대화된다. 따라서 각각의 x는 가장 큰 사후 확률 p(Ck&lt;/td&gt;
      &lt;td&gt;x)를 가지는 클래스로 분류되어야 함을 확인할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;기대-손실의-최소화&quot;&gt;기대 손실의 최소화&lt;/h4&gt;

&lt;p&gt;한 가지 예를 들어 , 환자의 데이터를 가지고 암의 여부를 추론한다고 해보자. 만약 암에 걸리지 않은 환자를 걸렸다고 판단하는 것보다 잘못된 진단으로 암에 걸린 환자를 건강하다고 판단했을 경우 심각한 결과를 초해라 수 있다. 이처럼 두 잘못된 판단의 결과가 다르게 나타날 수 있다. 이 경우에는 전자의 실수보다 후자의 실수를 줄이는 것이 중요하다.&lt;/p&gt;

&lt;p&gt;비용함수라고도 부르는 손실 함수를 도입함으로써 이러한 문제들을 더 공식화할 수 있다. 손실 함수는 어떤 결정이나 행동이 일어났을 때의 손실을 전체적으로 측정하는 함수다. 이를 활용하면 우리의 목표를 발생하는 전체 손실을 최소화하는 것으로 변경할 수가 있다.&lt;/p&gt;

&lt;p&gt;실제 클래스 \(C_{k} \)인 새 입력값 X를 클래스 \(C_{j} \)로 분류했다고 가정해보자. 이 과정에서 우리는 \(L_{k,j} \)로 표현할 수 있는 손실을 발생시키게 된다.
\(L_{k,j} \)는 손실 행렬의 k,j번째 원소로 볼 수 있다. 예를 들어 암 환자 분류 예시에 대해서 다음과 같은 손실 행렬을 가정하여 결과에 따른 손실을 다르게 줄 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/17.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/17.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;손실 함수를 최소화하는 해가 최적의 해다. 하지만 손실 함숫값은 알려져 있지 않는 실제 클래스값을 알아야만 계산이 가능하다. 주어진 입력 벡터 X에 대해서 실제 클래스값에 대한 불확실성은 결합 확률 분포 p(x,ck)로 표현된다. 그렇기 때문에 우리는 이 분포에 대해 계산한 평균 손실을 최소화하는 것을 목표로 삼을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ E(L) = \sum_{k}\sum_{j}\int_{R_{j}}L_{k,j}p(\textbf{x},C_{k})dx \]&lt;/p&gt;

&lt;p&gt;확률의 곱의 법칙을 활용하면 \( p(x,C_{k}) = p(C_{k} \mid x)p(x) \)임을 알 수 있고 공통 인자 p(x)를 제거할 수 있다. 따라서 기대 손실을 최소화하는 결정 법칙은 각각의 x를 다음 식을 최소화하는 클래스 j에 할당하는 것이다.&lt;/p&gt;

&lt;p&gt;\[ \int_{k} L_{k,j}p(C_{k} \mid \textbf{x})\]&lt;/p&gt;

&lt;p&gt;각각의 클래스에 대한 사후 확률 \( P(C_{k} \mid x) \)를 알고 나면 이 방법을 쉽게 시행할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;거부옵션&quot;&gt;거부옵션&lt;/h4&gt;

&lt;p&gt;결합확률 \( p(x,C_{k}) \)들이 비슷한 값을 가지고 있을 경우 이러한 구역들로 인해서 분류 오차가 생겨나기도 한다. 이 구역들에 대해서는 해당 구역이 어떤 클래스에 속할지에 대한 우리의 확신 정도가 비교적 적은 것이다. 이 처럼 결정을 내리기 힘든 지역에 대해서는 결정을 피하는 ‘ 거부 옵션’을 주는 것이 적절할 수도 있다. 임계값 θ를 설정해서 사후 확률 \( P(C_{k} \mid x) \)들 중에서 가장 큰 값이 θ보다 작거나 같을 경우에 해당 입력값 X를 거부하는 방식으로 이를 시행할 수 있다. 하나의 연속 입력 변수 x와 두 개의 클래스의 경우에 대한 예시는 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/18.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/18.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;손실 행렬이 주어진 경우에는 기대 손실값을 최소화하도록 거부 옵션을 확장할 수 있다. 이 경우에는 거부 결정이 내려졌을 때 발생하는 손실값을 고려 사항에 포함해야 한다.&lt;/p&gt;

&lt;p&gt;추론과 결정에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.5-Decision-Theory/&quot;&gt;1.5 Decision Theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 27, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.3 Model Selection - 1.4 The Curse of Dimensionality]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.3-Model-Selection-1.4-The-Curse-of-Dimensionality/" />
  <id>http://localhost:4000/articles/[PRML]1.3 Model Selection - 1.4 The Curse of Dimensionality</id>
  <published>2022-02-26T07:08:50+09:00</published>
  <updated>2022-02-26T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;h4 id=&quot;모델-선택&quot;&gt;모델 선택&lt;/h4&gt;

&lt;p&gt;주어진 한 모델에서 매개변수의 값을 결정하는 것뿐만이 아니라 다양한 여러 모델들을 고려하여 해당 응용 사례에 가장 적합한 모델을 선택해야 할 경우도 있다.&lt;/p&gt;

&lt;p&gt;최대 가능도 접근법에서 이미 확인한 것과 같이 훈련 집한에서의 좋은 성능이 반드시 좋은 예측 성능을 보장해 주지는 못한다. 이는 과적합 문제 때문이다. 이를 해결하기 위한 한 가지 방법은 데이터가 충분할 경우 일부의 데이터만 사용하여 다양한 모델과 모델의 매개변수들을 훈련시키고 독립적인 데이터 집합인 검증 집합에서 이 모델들과 매개변수들을 비교/선택하는 것이다. 만약 한정된 크기의 데이터 집합이라면 시험 집합을 따로 분리해 두고 이 집합을 통해서 선택된 모델의 최종 성능을 판단하는 것이 좋을 수도 있다.&lt;/p&gt;

&lt;p&gt;하지만, 실제 경우에는 훈련과 시험을 위한 데이터의 공급이 제한적이다. 이런 상황에서는 교차 검증법이 한 가지 방법이 된다.
교차 검증법을 활용하면 전체 데이터 (s) 중 데이터 (s-1)/s 비율만틈 훈련에 사용하고. 모든 데이터를 다 활용하여 성능을 추정할 수 있다. 특히 데이터가 부족할 경우에는 S=N( N은 전체 데이터 숫자) 의 교차 검증법으 고려할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/12.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/12.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그림과 같이 S = N 교차 검증법은 데이터 포인트 하나만(다홍색)  남겨 두고 모델을 훈련시키는 테크닉이다.&lt;/p&gt;

&lt;p&gt;교차 검증법의 주요 단점은 S의 수가 늘어남에 따라서 모델 훈련의 시행 횟수가 함께 늘어난다는 것이다. 또 다른 문제점은 한 가지 모델에 여러 가지의 복잡도 매개변수가 있을 경우에 발생한다. 여러 매개변수들의 조합들을 확인해보기 위해서는 최악의 경우 매개변수 숫자에 대해 기하급수적인 수의 훈련 실행이 필요할지도 모른다.&lt;/p&gt;

&lt;p&gt;이보다 더 나은 이상적인 방식에서는 훈련 집합만을 활용해서 여러 종류의 초 매개변수와 각 모델 종류에 대한 비교를 한 번의 훈련 과정동안 시행할 수 있어야 한다. 이를 위해서는 오직 훈련 집합만을 활용하는 성능 척도가 필요하다. 또한 이 척도는 과적합으로 인한 편향으로부터 자유로워야 한다.&lt;/p&gt;

&lt;p&gt;역사적으로 다양한 정보 기준들이 최대 가능도 방법의 편향 문제에 대한 대안으로 제시되어 왔다. 예를 들어서 &lt;b&gt;아카이케의 정보량 기준, 베이지안 정보 기준&lt;/b&gt; 등이 있다.&lt;/p&gt;

&lt;h4 id=&quot;차원의-저주&quot;&gt;차원의 저주&lt;/h4&gt;

&lt;p&gt;실제 사례에서는 입력 변수가 하나가 아닌 많은 종류의 입력 변수로 구성된 고차원 공간을 다뤄야 한다.
이 문제에 대해 좀 더 살펴보기 위해서 다음 예시를 살펴보자.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/13.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/13.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이 데이터는 오일,물,가스가 혼합되어 운반되는 송규관에서 측정된 데이터다. 이 세 가지 원료는 서로 다른 ‘균질’,’환형’,’층상’이라는 세 가지 방식으로 송유관 안에 혼한되어 있을 수 있다. 그리고 각각의 방식 내에서 세 가지 성분의 배합 비율 역시 다를 수 있다. 각 데이터 포인트의 입력값은 12차원의 입력 벡터로 표현되며, 이는 감사선 농도계를 이용하여 측정한 것이다.&lt;/p&gt;

&lt;p&gt;위의 그림은 데이터 집합에서 선별된 100개의 포인트에 대해서 입력 변수 x6와 x7을 표현한 산포도이다. 각 데이터 포인트에는 세 가지 혼합 방식 중 어떤  것인지 색으로 분류하였다. 우리의 목표는 각 데이터 포인트를 훈련 집합으로 사용해서 새로운 관측값을 분류하는 것이다.&lt;/p&gt;

&lt;p&gt;가장 단순한 접근법은 다음 그림과 같이 입력 공간을 같은 크리의 여러 칸들로 나누는 것이다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/14.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/14.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;클래스를 예측하고 싶은 어떤 시험 포인트가 주어졌을 경우에는 일단 해당 포인트가 속한 칸을 찾아내고. 그 칸에 속한 훈련 포인트들을 모두 찾는다. 그리고 해당 칸에 속한 훈력 포인트들의 클래스들을 살펴보고 그중 대다수인 것을 시험 포인트의 클래스로 지정한다.&lt;/p&gt;

&lt;p&gt;이 접근법에는 심각한 문제가 있다. 입력 변수가 더 많아지는 경우, 공간을 단위 크기로 나눌 때, 공간의 차원이 높아짐에 따라서 필요한 칸의 숫자가 기하급수적으로 늘어나는 것이다. 기하급수적으로 많은 칸이 있다면 각 칸이 비어 있지 않도록 하기 위해서 그만큼 많은 수의 훈련 데이터가 필요하다. 이를 그림으로 표현하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/15.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/15.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;고차원에서 발생할 수 있는 심각한 문제를 &lt;b&gt;차원의 저주&lt;/b&gt;라고 지칭한다. 
차원의 저주는 패턴 인식을 고차원 입력값에 적용하는 데 있어서의 중요한 문제점을 시사한다. 하지만 그렇다고 해서 고차원 입력값에 대해 사용할 수 있는 효과적인 패턴 인식 테크닉을 찾아내는 것이 불가능한 일이 아니다. 그 이유는 2가지이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;실제 세계의 고차원 데이터들의 경우에 유의미한 차원의 수는 제한적이다.&lt;/li&gt;
  &lt;li&gt;대부분의 경우 입력값에 작은 변화가 일어나면 표적값에서도 작은 변화만 일어나게 되고, 지역 보간법 등의 테크닉을 적용하여 새로운 입력 변수에 대한 타킷 변수를 예측하는 것이 가능해진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;성공적인 패턴 인식 테크닉은 이 특성들을 활용하여 만들어지는 경우가 많다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.3-Model-Selection-1.4-The-Curse-of-Dimensionality/&quot;&gt;1.3 Model Selection - 1.4 The Curse of Dimensionality&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 26, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2 Probability theory(3)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory(3)/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory(3)</id>
  <published>2022-02-26T07:08:50+09:00</published>
  <updated>2022-02-26T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;이번에는 곡선 피팅 문제를 확률적 측면에서 살펴보자.&lt;/p&gt;

&lt;p&gt;곡선 피팅 문제의 목표는 N개의 입력값 \( X = (x1,….xn)^{T} \) 과 해당 표적값 \( t = (t1,…tn)^{T} \)가 주어진 상황에서 새로운 입력 변수 x가 
주어졌을 때 그에 대한 타깃 변수 t를 예측해 내는 것이다.
확률 분포를 이용해서 타깃 변수의 값에 대한 불확실성을 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;먼저, 주어진 x값에 대한 t값이 y(x,w)를 평균으로 가지는 가우시안 분포를 가진다고 가정한다(y(x,w)에 대한 설명은 1.1 참고 )
이를 바탕으로 다음의 조건부 분포를 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ “p(t \mid x,\textbf{w},b) = N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]&lt;/p&gt;

&lt;p&gt;여기서 β는 정밀도 매개변수로써 분포의 표본의 역수에 해당한다.
이 식을 도식화해 확인해보면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/7.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/7.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이제 훈련 집합 {X,t}를 바탕으로 최대 가능도 방법을 이용해서 알려지지 않은 매개변수 w와 β를 구해보도록 하자.
데이터는 위의 식에서 독립적으로 추출했다고 가정하면(i.i.d), 가능도 함수는 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ p(\textbf{t} \mid \textbf{x},\textbf{w},b) = \prod_{n=1}^{N}N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]&lt;/p&gt;

&lt;p&gt;계산의 편의를 위해 로그를 취해 로그 가능도 함수를 얻으면 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ ln p(\textbf{t} \mid \textbf{x},\textbf{w},b) = -\frac{\beta }{2}\sum_{n= 1}^{N}{(y(x_{n},\textbf{w})-t_{n})}^{2} + \frac{N}{2}ln\beta - \frac{N}{2}ln(2\pi) \]&lt;/p&gt;

&lt;p&gt;다항식 계수(w)의 최대 가능도 해를 구해보면 w와 관련된 것은 오른쪽 식의 맨 왼쪽만 해당한다. 따라서 음의 로그이기 때문에 이를 최소화하는 것이다. 즉 가능도 함수를 최대화하려는 시도의 결과로 제곱합 오차 함수를 유도할 수 있는 것이다.&lt;/p&gt;

&lt;p&gt;마찬가지로 가우시안 조건부 분포의 정밀도 매개변수 β를 결정하는 데도 최대 가능도 방법을 사용할 수 있다. 로그 가능도를 β에 대해 최대화하면 다음의 식이 도출된다.&lt;/p&gt;

&lt;p&gt;\[ \frac{1}{B_{ML}} = \frac{1}{N}\sum_{n = 1}^{N}(y(x_{n},w_{ML})-t_{n})^{2} \]&lt;/p&gt;

&lt;p&gt;매개변수 w와  β를 구했으니, 이제 이를 바탕으로 새로운 변수 x에 대해 예측값을 구할 수 있다.
확률모델을 사용하고 있으므로 예측값은 t에 대한 예측 분포로 표현될 것이다(점 X)
최대 가능도 매개변수들을 식(1)에 대입하면 다음을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(t \mid x,w_{ML},\beta_{ML}) = N(t \mid  y(x,w_{ML}),\beta^{-1}_{ML}) \]&lt;/p&gt;

&lt;p&gt;이제 다항 계수 w에 대한 사전 분포를 도입할 것이다. 문제의 단순화를 위해서 다음 형태를 지닌 가우시안 분포를 사용할 것이다.
\[ p(w \mid \alpha) = N( w \mid 0,\alpha^{-1}\textbf{I}) = (\frac{\alpha^{\frac{M+1}{2}}}{2\pi})exp(-\frac{\alpha}{2}w^{T}w)\]&lt;/p&gt;

&lt;p&gt;식에 대해 설명을 하자면 α는 분포의 정밀도이며 모델 매개변수의 분포를 제어하는 초매개변수이다. 또한 M+1은 m차수 다항식 벡터 w의 원소의 개수이다.&lt;/p&gt;

&lt;p&gt;따라서 베이지안 정리에 의해 다음이 성립한다( 자세한 내용은 1.2(2)를 참고)&lt;/p&gt;

&lt;p&gt;\[ p(w \mid x,t,\alpha, \beta ) \propto p(t \mid t,w,\beta)p(w \mid \alpha) \]&lt;/p&gt;

&lt;p&gt;이제 주어진 데이터에 대해 가장 가능성 높은 w를 찾는 방식으로 w를 결정할 수 있다.
즉, 사후 분포를 최대화하는 방식으로 w를 결정할 수 있다. 이 테크닉을 &lt;b&gt;최대 사후 분포&lt;/b&gt;라 한다.&lt;/p&gt;

&lt;p&gt;따라서 사후 확률의 최댓값을 찾는 것이 다음 식 값의 최솟값을 찾는 것과 동일함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \frac{\beta}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w}) - t_{n})^{2} + \frac{\alpha}{2}\textbf{w}^{T}\textbf{w} \]&lt;/p&gt;

&lt;p&gt;따라서 사후 분포를 최대화하는 것이 정규화 매개변수가 \( \lambda = \frac{α}{β} \) 로 주어진 식의 정규화된 제곱합 오차 함수(1.1참고)를 최소화하는 것과 동일함을 확인할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;베이지안-곡선-피팅&quot;&gt;베이지안 곡선 피팅&lt;/h4&gt;

&lt;p&gt;비록 사전 분포 p(w | α)를 포함시키긴 했지만, 여전히 w에 대해 점 추정을 하고 있기 때문에 아직은 완벽한 베이지안 방법론을 구사한다고 말할 수 없다. 완전한 베이지안적 접근을 위해서는 확률의 합의 법칙과 곱의 법칙을 일괄적으로 적용해야 한다. 이를 위해서는 모든 w값에 대해 적분을 시행해야 한다. 이러한 주변화가 패턴 인식에서의 베이지안 방법론의 핵심이다.
(주변화에 대하여 좀 더 설명하자면, 여러개의 확률 변수로 구성된 조합 확률 분포에서 한 가지 변수에 대한 확률값을 추정하기 위해 나머지 변수를 모두 적분하여 제거하는 과정을 말한다.)&lt;/p&gt;

&lt;p&gt;곡선 피팅 문제의 새로운 변수 x에 대한 표적값 t를 예측하기 위해 예측 분포 p(t|x,X,t)를 구해 보자. 여기서는 매개변수 α 와 β는 고정되어 있으며, 미리 알려졌다고 가정한다.
단순히 말하자면 베이지안 방법은 단지 확률의 합과 곱의 법칙을 계속적으로 적용하는 것이다. 이를 통해 예측 분포를 다음과 같은 형태로 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(t \mid x,\textbf{x},t) = \int p(t \mid x,\textbf{w})p(w \mid \textbf{x},t)dw\]&lt;/p&gt;

&lt;p&gt;p(w|x,t)는 매개변수들에 대한 사후 분포이다.
위 식의 적분을 시행하면 예측 분포가 다음의 식과 같이 가우시안 분포로 주어진다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(t \mid x,\textbf{x},t) = N(t \mid m(x),s^{2}(x)) \]&lt;/p&gt;

&lt;p&gt;여기서 예측분포의 평균과 분산이 x에 종속되어 있음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 평균과 분산은 다음과 같다&lt;/p&gt;

&lt;p&gt;\[ m(x) = \beta \phi (x)^{T}\textbf{S} \sum_{n=1}^{N}\phi(x_{x_{n}})t_{n} \]
\[ s^{2}(x) = \beta^{-1} + \phi(x)^{T} \textbf{S} \phi(x)\]&lt;/p&gt;

&lt;p&gt;식에 대해 설명하자면, 분산의 \(\beta^{-1} \)은 타깃 변수의 노이즈로 인한 예측값 t의 불확실성이며 최대가능도 해의 \(\beta^{-1} \)과 같다,
또한 분산의 두 번째 항은 w의 불확실성으로 부터 기인한다.&lt;/p&gt;

&lt;p&gt;행렬 S 는 다음처럼 주어진다.&lt;/p&gt;

&lt;p&gt;\[\textbf{S}^{-1} = \alpha \textbf{I} + \beta \sum_{n=1}{N} \phi(x_{n})\phi(x_{n})^{T} \]&lt;/p&gt;

&lt;p&gt;I 는 단위 행렬이며 ø(x)는 각각의 원소가 i = 0,…,M에 대해 \( \phi_{i}(x) = x^{i} \)인 벡터이다&lt;/p&gt;

&lt;p&gt;마지막으로 합성 사인 회귀 문제에 대한 예측 분포의 시각화를 통해 확인해보면서 이해를 돕도록 한다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/11.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/11.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이는 베이지안적 방법을 통해 구한 M = 9인 다항식 곡선 피팅 문제의 예측 분포이다.
빨간색 선은 예측 분포의 평균값을, 그리고 빨간색 영역은 평균값으로부터 ±1 표준 편찻값을 가지는 부분을 표현한 것이다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory(3)/&quot;&gt;1.2 Probability theory(3)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 26, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2. Probability theory (2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory(2)/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory(2)</id>
  <published>2022-02-25T07:08:50+09:00</published>
  <updated>2022-02-25T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;지금까지 확률을 ‘반복 가능한 임의의 사건의 빈도수’라는 측면에서 살펴보았다. 이러한 해석을 고전적 또는 빈도적 관점이라 일컫는다.
이번에는 더 포괄적인 베이지안 관점에서 살펴보자. 베이지안 관점을 이용하면 확률을 이용해서 불확실성을 정량화하는 것이 가능하다.&lt;/p&gt;

&lt;p&gt;베이지안 관점을 사용하면 모델 매개변수의 불확실성을 설명할 수 있고 더 나아가 모델 그 자체를 선택하는 데 있어서도 유용하다.&lt;/p&gt;

&lt;p&gt;앞에서 설명한 다항식 곡선 피팅(1.1장) 예시의 매개변수 w에 적용해보자&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫 번째로 데이터를 관측하기 전의 w에 대한 우리의 가정을 사전 확률 분포 p(w)로 표현할 수 있다.&lt;/li&gt;
  &lt;li&gt;관측된 데이터 D = {t1,t2,,,,,tn}은 조건부 확률 p(D|w)로써 작용하게 된다.
이 경우 베이지안 정리는 다음 형태를 띤다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\( p(w \mid D) = \frac{p(D \mid w)p(w)}{p(D)} \) 식(1)&lt;/p&gt;

&lt;p&gt;자세히 설명하면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(p(w \mid D) \): D를 관측한 후의 w에 대한 불확실성을 사후 확률로 표현&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(p(D \mid w) \) : 각각의 다른 매개변수 벡터 w에 대해 관측된 데이터 집합이 얼마나 그렇게 나타날 가능성이 있는지를 표현한 가능도 함수 
           (가능도 함수는 w에 대한 확률 분포가 아니며, 따라서 w에 대해 가능도 함수를 적분하여도 1이 될 필요가 없다)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\( p(w) \): 데이터를 관측하기 전의 w에 대한 우리의 가정, 사전 확률&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\( p(D) \) : 사후 분포가 적합한 확률 분포가 되고 적분값이 1이 되도록 하기 위한 정규화 상수&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;가능도 함수에 대한 정의를 바탕으로 베이지안 정리를 다음처럼 적을 수가 있다.&lt;/p&gt;

&lt;p&gt;사후 확률  ∝ 가능도 x 사전확률 ( 각 값은 전부 w에 대한 함수)&lt;/p&gt;

&lt;p&gt;식(1)의 양쪽 변을 w에 대해 적분하면 베이지안 정리의 분모를 사전확률과 가능도 함수로 표현 가능하다&lt;/p&gt;

&lt;p&gt;\[p(D) = \int p(D \mid \textbf{w})p(\textbf{w})d\textbf{w} \]&lt;/p&gt;

&lt;p&gt;여기서 가능도 함수의 역할을 살펴보면 빈도적 확률 관점과 베이지안 확률 관전에서 다르다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;빈도적 확률 관점 : w가 고정 매개변수로 여겨지며, w의 값은 어떤 형태의 ‘추정값’을 통해서 결정된다. 그리고 추정에서의 오류는
                            가능한 데이터 집합들 D의 분포를 고려함으로써 구할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;베이지안 확률 관점 : 오직 하나의 (실제로 관측될) 데이터 집합 D만 존재하며, 매개변수의 불확실성은 w의 확률 분포를 통해 표현한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;u&gt;빈도적 확률 관점&lt;/u&gt;에서 널리 사용되는 추정값 중 하나는 바로 &lt;b&gt;최대가능도&lt;/b&gt;이다.&lt;/p&gt;

&lt;p&gt;최대가능도를 사용할 경우에 w의 가능도 함수 p(D|w)를 최대화하는 값으로 선택한다.
(머신러닝에서 종종 음의 로그 가능도 함숫값을 오차함수라고 일컫는다. 음의 로그 함수는 단조 감소하는 함수이기 때문에 가능도의 최댓값을 찾는 것이 오차를 최소화하는 것과 동일하다 -&amp;gt; 자세한 내용은 CS229 강의를 정리하면서 설명할 예정이다)&lt;/p&gt;

&lt;p&gt;또한, 빈도적 확률론자들이 오차를 측정하는 방법 중 하나가 부트스트랩이다.
예를 들어 설명하면, 원 데이터 집합이 N개인 데이터 포인트 X = {x1,x2,,,,xn}가 있다고 가정해보자.
X에서 N개의 데이터 포인트를 임의로 복원 추출하여 데이터 집합 Xb를 만든다. 
이 과정을 L번 반복하면 원래 데이터 집합의 표본에 해당하는 크기 N의 데이터 집합을 L개 만들 수 있다.
각각의 부트스트랩 데이터 집합에서의 예측치와 실제 매개변수 값과의 차이를 바탕으로 매개변수 추정값의 통계적 정확도를 판단할 수 있다.&lt;/p&gt;

&lt;p&gt;베이지안 관점의 장점 중 하나는 사전 지식을 추론 과정에서 자연스럽게 포함시킬 수 있다.
동전 10개를 던졌는데 모두 앞면이 나왔다고 가정하자. 빈도적 관점에서는 미래의 모든 동전 던지기에서 앞면만 나올 것이라고 예측한다.대조적으로 베이지안 관점에서는 적당히 합리적인 사전 확률을 사용한다면 이렇게까지 과도한 결론이 나오지 않을 것이다.&lt;/p&gt;

&lt;p&gt;하지만, 베이지안 관점에서는 사전 확률의 선택에 따라 결론이 나오기 때문에 추론 과정에서 주관이 포함될 수밖에 없고 실제로 좋지 않은 사전 분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 높은 확신으로 내놓기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;가우시안-분포&quot;&gt;가우시안 분포&lt;/h4&gt;

&lt;p&gt;이제 가장 중요한 연속 활률 분포 하나를 살펴보고자 한다. 바로 정규 분포라고도 불리는 가우시안 분포이다.&lt;/p&gt;

&lt;p&gt;단일 실수 변수 x에 대해서 가우시안 분포는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ N(x \mid \mu ,\sigma ^{2}) = \frac{1}{\sqrt{2\pi \sigma ^{2}}}exp(-\frac{(x-\mu)^{2}}{2\sigma^{2}}) \]&lt;/p&gt;

&lt;p&gt;위의 식은 두 개의 매개변수 μ(평균),  \(σ^{2} \)(분산)에 의해 통제된다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/6.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/6.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;위의 가우시안 식으로부터 가우시안 분포가 다음의 성질은 만족함을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[N(x \mid \mu ,\sigma ^{2})&amp;gt; 0 \]&lt;/p&gt;

&lt;p&gt;가우시안 분포가 정규화되어 있다는 것 또한 쉽게 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \int_{-\infty }^{\infty}N(x \mid \mu,\sigma^{2})dx = 1 \]&lt;/p&gt;

&lt;p&gt;가우시안 분포를 따르는 임의의 x에 대한 함수의 기댓값을 구할 수 있다. 특히 x의 평균값은 다음과 같다&lt;/p&gt;

&lt;p&gt;\[ E(x) = \int_{-\infty }^{\infty}N(x \mid \mu ,\sigma ^{2}) x dx = \mu \]&lt;/p&gt;

&lt;p&gt;이와 비슷하게 x에 대한 이차 모멘트를 계산해 보자&lt;/p&gt;

&lt;p&gt;\[ E(x^{2}) = \int_{-\infty }^{\infty}N(x \mid \mu ,\sigma ^{2}) x^{2} dx = \mu^{2} +\sigma^{2} \]&lt;/p&gt;

&lt;p&gt;이를 통해 x의 분산을 다음과 같이 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ var(x) = E(x^{2}) - E(x)^{2} = \sigma^{2} \]&lt;/p&gt;

&lt;p&gt;분포의 최댓값을 최빈값(mode)이라 하는데, 가우시안 분포의 경우에는 최빈값과 평균값이 동일하다.&lt;/p&gt;

&lt;p&gt;다음으로는 연속 변수로 이루어진 D차원 벡터 X에 대한 가우시안 분포를 살펴보도록 하자&lt;/p&gt;

&lt;p&gt;\[ N(X \mid \mu,\Sigma ) = \frac{1}{(2\pi) ^{\frac{D}{2}}}\frac{1}{ \mid \Sigma \mid ^{\frac{1}{2}}}exp(-\frac{1}{2}(X-\mu)^{T}\Sigma^{-1}(X-\mu)) \]&lt;/p&gt;

&lt;p&gt;이 식은 가우시안 분포의 가능도 함수에 해당한다.&lt;/p&gt;

&lt;p&gt;관측된 데이터 집합을 바탕으로 확률 분포의 매개변수를 결정하는 표준적인 방법 중 하나는 가능도 함수를 최대화하는 매개변수를 찾는 것이다.&lt;/p&gt;

&lt;p&gt;위의 식에 로그를 취하여 (수학적 분석, 계산을 쉽게하기 위해서 또한 언더플로우 방지) 로그가능도 함수를 다음과 같이 적을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ lnp(X \mid \mu,\sigma^{2} ) =-\frac{1}{2\sigma^{2}}\sum_{n=1}^{N}(x_{n} - \mu)^{2} - \frac{N}{2}ln\sigma^{2}-\frac{N}{2}ln(2\pi) \]&lt;/p&gt;

&lt;p&gt;μ에 대해 이 식의 최댓값을 찾으면 다음의 최대 가능도해를 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_{n} \]&lt;/p&gt;

&lt;p&gt;이는 바로 관찰된 값{xn}들의 평균인 표본평균이다&lt;/p&gt;

&lt;p&gt;이와 비슷한 방식으로 최댓값을 \(σ^{2} \)에 대해 찾으면 분산에 대한 최대 가능도 해를 다음과 같이 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;\[ \sigma^{2}(ML) = \frac{1}{N}\sum_{n=1}^{N}(x_{n} - \mu_{ML})^{2}\]&lt;/p&gt;

&lt;p&gt;이는 표본 평균에 대해 계산된 표본 분산이다(가우시안 분포의 경우, μ,  \( σ^{2} \)에 대한 해가 연관이 없기 때문에 계산 순서를 변경해도 무방하다)&lt;/p&gt;

&lt;p&gt;하지만, 최대가능도 방법에는 한계가 있다
최대가능도 방법이 구조적으로 분포의 분산을 과소평가하게 된다.즉 편향된다.
최대가능도 해인 μ,  \( σ^{2} \)은 데이터 집합 x1,….,xn의 함수다. 각 데이터 집합의 값에 대해 이들의 기댓값을 고려해보자&lt;/p&gt;

&lt;p&gt;\[ E(\mu_{ML}) = \mu \]
\[ E(\sigma^{2}_{ML}) = (\frac{N-1}{N})\sigma^{2} \]&lt;/p&gt;

&lt;p&gt;여기서 분산이 (N-1/N)만큼 과소평가된다.
최대 가능도 방법의 편향 문제는 우리가 앞에서 살펴본 다항식 곡선 피팅에서의 과적합 문제의 근본적인 원인이 된다.
또한, 데이터 포인트의 개수인 N이 커질수록 최대 가능도 해에서의 편향치는 점점 줄어든다&lt;/p&gt;

&lt;p&gt;곡선 피팅에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory(2)/&quot;&gt;1.2. Probability theory (2)&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 25, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.2 Probability theory]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.2-Probability-theory/" />
  <id>http://localhost:4000/articles/[PRML]1.2 Probability theory</id>
  <published>2022-02-24T04:01:50+09:00</published>
  <updated>2022-02-24T04:01:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;패턴 인식에서 ‘불확실성’은 측정할 때의 노이즈를 통해서도 발생하고 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.
따라서, 확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해 준다.&lt;/p&gt;

&lt;p&gt;예시를 들어보자&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/5.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;이 예시에서는 X,Y라는 두 가지 확률 변수가 존재한다. X는 \(x_{i} \) (i = 1,….,M)중 아무 값이나 취할 수 있고 Y는 \(y_{j} \) (j = 1,…,L)중 아무 값이나 취할 수 있다. 또한, X와 Y각각에서 표본을 추출하는 시도를 N번 한다고 가정한다.
\(n_{i,j} \)는 \( X = x_{i}, Y = y_{j} \) 인 시도 개수를 의미하며, \(c_{i} \)는 Y 값과는 상관없이 \(X= x_{i} \)인 시도의 숫자, \(r_{j} \)는  X값과 상관없이 \(Y=y_{j} \)인 시도의 숫자를 의미한다.&lt;/p&gt;

&lt;p&gt;\( X = x_{i}, Y = y_{j} \) 일 결합 확률은 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i},Y = y_{i}) = \frac{n_{i,j}}{N} \]&lt;/p&gt;

&lt;p&gt;비슷하게 Y값과 무관하게 X가 \(x_{i} \)값을 가질 확률을 다음과 같다&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) =\frac{c_{i}}{N} \]&lt;/p&gt;

&lt;p&gt;이 두 식을 이용하여 다음을 도출해 낼 수 있다.&lt;/p&gt;

&lt;p&gt;\[p(X = x_{i}) = \sum_{j=1}^{L}p(X = x_{i},Y = y_{j}) \]&lt;/p&gt;

&lt;p&gt;이것이 확률의 &lt;b&gt;합의 법칙&lt;/b&gt;이다. 여기서 \(P(X = x_{i}) \)는 주변 확률이라 불린다.&lt;/p&gt;

&lt;p&gt;여기서 \(X = x_{i} \)인 사례들만 고려해보자. 그들 중에서 \(Y = y_{i} \)인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 \(p(Y = y_{i} | X = x_{i}) \)로 적을 수 있으며
이를 &lt;b&gt;조건부 확률&lt;/b&gt;이라고 부른다&lt;/p&gt;

&lt;p&gt;\[ p(Y = y_{i} \mid X = x_{i}) = \frac{n_{i,j}}{c_{i}} \]&lt;/p&gt;

&lt;p&gt;지금까지의 식을 이용해서 다음의 관계를 도출할 수 있다.&lt;/p&gt;

&lt;p&gt;\[ p(X = x_{i} \mid Y = x_{j}) = \frac{n_{i,j}}{c_{i}} = \frac{n_{i,j}}{c_{i}}\cdot \frac{c_{i}}{N} = p(Y = y_{j} \mid X = x_{i})p(X=x_{i}) \]&lt;/p&gt;

&lt;p&gt;이것이 바로 확률의&lt;b&gt; 곱의 법칙&lt;/b&gt;이다&amp;lt;/p&amp;gt;&lt;/p&gt;

&lt;p&gt;이제, 곱의 법칙과 합의 법칙, 대칭성 p(X,Y) = p(Y,X)로 부터 조건부 확률 간의 관계인 다음 식을 도출해 낼 수 있다.
(여기서 부터는 간단하게 확률 변수 X에서 분포를 표현할 때는 p(X)라 적고 특정 값 xi에서의 분포를 표현할 때는 \(p(x_{i}) \)로 적기로 한다)&lt;/p&gt;

&lt;p&gt;\[p(Y \mid X) = \frac{p(X\mid Y)p(Y)}{p(X)} = \frac{p(X\mid Y)p(Y)}{\sum_{Y}p(X\mid Y)p(Y)} \]&lt;/p&gt;

&lt;p&gt;이를 &lt;b&gt;베이즈 정리&lt;/b&gt;라고 한다( 책의 전반에 걸쳐 중요한 역할을 한다)&lt;/p&gt;

&lt;p&gt;여기서 분모는 왼쪽 항을 모든 Y값에 대하여 합했을 때 1이 되도록 하는 역할을 한다.
베이지안 정리는 다음과 같이 해석할 수 있다.
확률 p(A|B)를 알고 있을 때, 관계가 정반대인 확률 p(B|A)를 계산하는 것으로 여기서 P(B)는 사전 확률, p(B|A)는 사후 확률에 해당한다.
여기서, 두 확률 변수가 독립이라면, p(X,Y) = p(X)p(Y) 이다.&lt;/p&gt;

&lt;h4 id=&quot;확률-밀도&quot;&gt;확률 밀도&lt;/h4&gt;

&lt;p&gt;이번에는 연속적인 변수에서의 확률에 대해 알아본다.&lt;/p&gt;

&lt;p&gt;만약 실수 변수 x가 (x,x+δx)구간 안의 값을 가지고 그 변수의 확률이 p(x)δx로 주어진다면, p(x)를 x의 확률 밀도라고 부른다.
이때, x가 (a,b) 구간 사이의 값을 가질 확률은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ p(x \in (a,b)) = \int_{a}^{b}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서, 확률은 양의 값을 가지고 x의 값은 실축선상에 존재해야 하기 때문에 다음의 두 조건을 만족시켜야 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\( p(x) \geq 0 \)&lt;/li&gt;
  &lt;li&gt;\( \int_{-\infty }^{\infty}p(x)dx = 1 \)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;누적-분포-함수&quot;&gt;누적 분포 함수&lt;/h4&gt;

&lt;p&gt;x가 (-∞,z) 범위에 속할 확률은 &lt;b&gt;누적 분포 함수 &lt;/b&gt; 로 표현된다.&lt;/p&gt;

&lt;p&gt;\[ P(z) = \int_{-\infty }^{z}p(x)dx \]&lt;/p&gt;

&lt;p&gt;여기서 P’(x) = p(x)이다.&lt;/p&gt;

&lt;p&gt;만약 x가 이산 변수일 경우 p(x)를  &lt;b&gt; 확률 질량 함수 &lt;/b&gt;라고 부르기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;기댓값&quot;&gt;기댓값&lt;/h4&gt;
&lt;p&gt;기댓값은 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값을 의미한다. 이산 분포의 경우 기댓값은 다음과 같이 주어진다.&lt;/p&gt;

&lt;p&gt;\[ E(f) = \sum_{x}p(x)f(x) \]&lt;/p&gt;

&lt;p&gt;여기서 p(x)는 각 x값에 해당하는 확률이며 이것을 가중치로 사용한 가중 평균을 구하는 것으로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;연속 변수의 경우에는 해당 확률 밀도에 대해 적분을 시행해서 기댓값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(f) = \int p(x)f(x)dx \]&lt;/p&gt;

&lt;p&gt;공분산에 해당하는 특징은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E[aX + b] = aE[X] + b&lt;/li&gt;
  &lt;li&gt;E[X + Y] = E[X] + E[Y]&lt;/li&gt;
  &lt;li&gt;E[XY] = E[X]E[Y]&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;공분산&quot;&gt;공분산&lt;/h4&gt;

&lt;p&gt;공분산을 설명하기 앞서 분산부터 설명하면, f(x)의 분산은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[ var(f) = E((f(x) - E(f(x)))^{2}) \]&lt;/p&gt;

&lt;p&gt;이는 f(x)가 평균값 E[f(x)]로부터 전반적으로 얼마나 멀리 분포되었는지를 나타내는 값이다.&lt;/p&gt;

&lt;p&gt;이를 전개하여 정리하면 다음과 같다. (식의 이해를 돕기 위하여 상수인 E[f(x)] 부분을  μ라 표현)&lt;/p&gt;

&lt;p&gt;\( var(f) = E(f(x)^{2} -2\mu f(x) +\mu^{2})) \)  -&amp;gt; 공분산 특징 첫 번째 이용&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) -2\mu E(f(x)) +\mu^{2} \)&lt;/p&gt;

&lt;p&gt;\( = E(f(x)^{2}) - E(f(x))^{2} \)&lt;/p&gt;

&lt;p&gt;여기서 변수 x 그 자체에도 고려가능하다.&lt;/p&gt;

&lt;p&gt;다음으로 두 개의 확률 변수 x 와 y에 대해서 공분산은 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[ cov(x,y) = E((x - E(x))(y - E(y)) \]
\[= E(xy) - E(x)E(y) \]&lt;/p&gt;

&lt;p&gt;이는 x값과 y값이 얼마나 함께 같이 변동하는가에 대한 지표이며 만얀 x,y가 서로 독립적일 경우 공부산값은 0으로 간다.&lt;/p&gt;

&lt;p&gt;베이지안 확률에 대한 내용은 다음에 이어 설명하겠습니다.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.2-Probability-theory/&quot;&gt;1.2 Probability theory&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 24, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[ LECTURE 01]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/CS229-LECTURE-01/" />
  <id>http://localhost:4000/articles/[CS229]LECTURE 01</id>
  <published>2022-02-23T07:50:50+09:00</published>
  <updated>2022-02-23T07:50:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/CS229-LECTURE-01/&quot;&gt; LECTURE 01&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 23, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[베타 분포]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/blog/%E1%84%87%E1%85%A6%E1%84%90%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/" />
  <id>http://localhost:4000/blog/베타 분포</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/blog/%E1%84%87%E1%85%A6%E1%84%90%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/&quot;&gt;베타 분포&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[감마 분포]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/blog/%E1%84%80%E1%85%A1%E1%86%B7%E1%84%86%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/" />
  <id>http://localhost:4000/blog/감마 분포</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_b.jpg&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8426/7758832526_cc8f681e48_c.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/blog/%E1%84%80%E1%85%A1%E1%86%B7%E1%84%86%E1%85%A1-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9/&quot;&gt;감마 분포&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[1.1 Polynomial Curve Fitting]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/PRML-1.1-Polynomial-Curve-Fitting/" />
  <id>http://localhost:4000/articles/[PRML]1.1 Polynomial Curve Fitting</id>
  <published>2022-02-22T07:08:50+09:00</published>
  <updated>2022-02-22T07:08:50+09:00</updated>
  <author>
    <name>Cho min Hee</name>
    <uri>http://localhost:4000</uri>
    <email>aezjk56@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;이 글은 &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.&lt;/p&gt;

&lt;p&gt;다항식 곡선 피팅을 통해 일반적인 패턴 인식 / 머신 러닝 문제에서 고려되어야 할 사항들에 대해 직관적으로 살펴보자.&lt;/p&gt;

&lt;p&gt;다음과 같은 형태의 다항식이 있다.&lt;/p&gt;

&lt;p&gt;\[ y(x,\textbf{w})= w_{0}+w_{1}x+w2x^{2}+….+w_{M}x^{M} = \sum_{j = 0}^{M}w_{j}x^{j} \]&lt;/p&gt;

&lt;p&gt;이는 x에 대해서는 비선형지만, 계수 w에 대해서는 선형이다. 이를 기하학적으로 해석하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/1.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;먼저, 다항식을 훈련 집합 데이터에 피팅해서 계수의 값들을 정할 수 있다. 이때 훈련 집합과 함숫값 y(x,w)와의 오차를 측정하는 대표적인 오차 함수를 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;\[E(\textbf{w}) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w})-t_n)^2 \]&lt;/p&gt;

&lt;p&gt;E(w)를 초쇠화하는 w값을 선택함으로써 이 곡선 피팅 문제를 해결할 수 있다. 오차 함수가 이차 다항식의 형태를 지니고 있기 때문에 이 함수를 계수에 대해 미분하면 w에 대해 선형인 식이 나올 것이다. 이 오차 함수를 최소화하는 w는 유일한 값인 w*를 찾아낼 수 있다.&lt;/p&gt;

&lt;p&gt;다음으로 다항식의 차수 M을 결정하는 문제가 여전히 남아있다. 이를 Model Selection이라 불린다&lt;/p&gt;

&lt;p&gt;훈련 집합과 시험 집합 각각에 대해서 E(w*)의 잔차를 계산해 보자
평균 제곱근 오차(RMS) 를 통해 각각의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인할 것이다.&lt;/p&gt;

&lt;p&gt;평균 제곱근 오차는 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;\[E_{rms} = \sqrt{\frac{2E(w^*)}{N}} \]&lt;/p&gt;

&lt;p&gt;RMS를 통해 각가의 차수 M에 대해서 잔차가 어떻게 변화하는지 확인하면 다음과 같다&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/2.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/2.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;M값이 작을 경우에는 시험 집합의 오차가 상대적으로 커 UnderFitting이 되었으며 큰 경우, Overfitting이 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 수치적으로 확인했을 때, 차수 M에 따른 피팅 함수의 계수 w*의 값들이 M이 커짐에 따라 계수값의 단위 역시 커지는 것을 확인할 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/3.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/3.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;사용되는 데이터 집합의 크기가 달라지는 경우에는 어떤 일이 일어나는지 확인해 보자&lt;/p&gt;

&lt;p&gt;모델의 복잡도를 일정하게 유지시킬 때는 사용하는 데이터 수가 늘어날수록 과적합 문제가 완화되는 것을 확인할 수 있다. 즉 데이터 집합의 수가 클수록 더 복잡한 모델을 활용하여 피팅 가능하다. 
( 사실 베이지안 모델에서는 데이터 집합의 크기에 따라서 적합한 매개 변수의 수가 자동으로 정해지기 때문에 과적합 문제를 피해갈 수 있다)
이를 시각화하면 다음과 같다.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/PRML/4.png&quot; alt=&quot;image&quot;&gt;&lt;img src=&quot;/PRML/4.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;그렇다면 비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용하여 피팅하려면 어떻게 해야할까?
그 방법 중 하나가 정규화다&lt;/p&gt;

&lt;p&gt;오차 함수에 계수의 크기가 커지는 것을 막기 위한 패널티항을 추가하는 것이다. 식은 다음과 같다.&lt;/p&gt;

&lt;p&gt;\[\widetilde{E}(w) = \frac{1}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{W}) - t_{n})^2 + \frac{\lambda }{2}\left| w \right|^2 \]&lt;/p&gt;

&lt;p&gt;여기서, 이차 형식 정규화는 리지 회귀라고 부르고 뉴럴 네트워크의 맥락에서는 이를 가중치 감쇠라 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 지금까지의 결과를 바탕으로 모델 복잡도를 잘 선택하는 단순한 방법이 있다.&lt;/p&gt;

&lt;p&gt;그것은 바로 데이터 집합을 훈련 집합과 검증 집합으로 나누는 것이다.
여기서 훈련 집합은 계수 w를 결정하는데 사용하고 검증집합은 모델 복잡도를 최적화하는데 활용한다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/PRML-1.1-Polynomial-Curve-Fitting/&quot;&gt;1.1 Polynomial Curve Fitting&lt;/a&gt; was originally published by Cho min Hee at &lt;a href=&quot;http://localhost:4000&quot;&gt;MinPy&lt;/a&gt; on February 22, 2022.&lt;/p&gt;
  </content>
</entry>

</feed>