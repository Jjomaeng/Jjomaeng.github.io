I"0<p class="notice">이 글은 <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.</p>

<h3 id="가우시안-분포의-최대-가능도">가우시안 분포의 최대 가능도</h3>

<ul>
  <li>책에는 없지만, 앞의 내용을 복습할 겸 다변량 가우시안 분포부터 자세히 설명할 예정이다.</li>
  <li>먼저, 다변량 가우시안 분포부터 살펴보자.</li>
  <li>데이터 집합  \(X = ( x_{1},\cdots,x_{D} )^{T}\)이 주어졌으며, 관측값 \( {X_{d}}\)들이 다변량 가우시안 분포로 부터 독립적으로 추출되었다고 가정해 보자.</li>
  <li>이때 원 분산의 매개변수들을 최대 가능도 방법을 이용하여 추정할 수 있다.
\(X = \begin{pmatrix}
X_{1} \\
X_{2} \\
\vdots  \\
X_{d}
\end{pmatrix} \sim MVN(\mu,\Sigma)\)</li>
  <li>
    <p>여기서 \(\mu )\는 d x 1 벡터, \( \Sigma\)는 d x d행렬이 된다.</p>
  </li>
  <li>이러한 다변량 가우시안 분포의 pdf는 다음과 같이 쓸 수 있다.
\[ f(x_{i};\mu, \Sigma) = \frac{1}{(2\pi)^{\frac{d}{2}}}\]</li>
</ul>

:ET