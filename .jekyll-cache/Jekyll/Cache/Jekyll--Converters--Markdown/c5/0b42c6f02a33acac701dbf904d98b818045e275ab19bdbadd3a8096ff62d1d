I"<p>이 글은 <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.</p>

<p>이번에는 곡선 피팅 문제를 확률적 측면에서 살펴보자.</p>

<p>곡선 피팅 문제의 목표는 N개의 입력값 \( X = (x1,….xn)^{T} \) 과 해당 표적값 \( t = (t1,…tn)^{T} \)가 주어진 상황에서 새로운 입력 변수 x가 
주어졌을 때 그에 대한 타깃 변수 t를 예측해 내는 것이다.
확률 분포를 이용해서 타깃 변수의 값에 대한 불확실성을 표현할 수 있다.</p>

<p>먼저, 주어진 x값에 대한 t값이 y(x,w)를 평균으로 가지는 가우시안 분포를 가진다고 가정한다(y(x,w)에 대한 설명은 1.1 참고 )
이를 바탕으로 다음의 조건부 분포를 적을 수 있다.</p>

<p>\[ “p(t \mid x,\textbf{w},b) = N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]</p>

<p>여기서 β는 정밀도 매개변수로써 분포의 표본의 역수에 해당한다.
이 식을 도식화해 확인해보면 다음과 같다.</p>

<figure>
    <a href="/PRML/7.png" alt="image"><img src="/PRML/7.png" alt="image" /></a>
</figure>

<p>이제 훈련 집합 {X,t}를 바탕으로 최대 가능도 방법을 이용해서 알려지지 않은 매개변수 w와 β를 구해보도록 하자.
데이터는 위의 식에서 독립적으로 추출했다고 가정하면(i.i.d), 가능도 함수는 다음과 같이 주어진다.</p>

<p>\[ p(\textbf{t} \mid \textbf{x},\textbf{w},b) = \prod_{n=1}^{N}N(t \mid y(x,\textbf{w}),\beta ^{-1}) \]</p>

<p>계산의 편의를 위해 로그를 취해 로그 가능도 함수를 얻으면 다음과 같다.</p>

<p>\[ ln p(\textbf{t} \mid \textbf{x},\textbf{w},b) = -\frac{\beta }{2}\sum_{n= 1}^{N}{(y(x_{n},\textbf{w})-t_{n})}^{2} + \frac{N}{2}ln\beta - \frac{N}{2}ln(2\pi) \]</p>

<p>다항식 계수(w)의 최대 가능도 해를 구해보면 w와 관련된 것은 오른쪽 식의 맨 왼쪽만 해당한다. 따라서 음의 로그이기 때문에 이를 최소화하는 것이다. 즉 가능도 함수를 최대화하려는 시도의 결과로 제곱합 오차 함수를 유도할 수 있는 것이다.</p>

<p>마찬가지로 가우시안 조건부 분포의 정밀도 매개변수 β를 결정하는 데도 최대 가능도 방법을 사용할 수 있다. 로그 가능도를 β에 대해 최대화하면 다음의 식이 도출된다.</p>

<p>\[ \frac{1}{B_{ML}} = \frac{1}{N}\sum_{n = 1}^{N}(y(x_{n},w_{ML})-t_{n})^{2} \]</p>

<p>매개변수 w와  β를 구했으니, 이제 이를 바탕으로 새로운 변수 x에 대해 예측값을 구할 수 있다.
확률모델을 사용하고 있으므로 예측값은 t에 대한 예측 분포로 표현될 것이다(점 X)
최대 가능도 매개변수들을 식(1)에 대입하면 다음을 얻을 수 있다.</p>

<p>\[ p(t \mid x,w_{ML},\beta_{ML}) = N(t \mid  y(x,w_{ML}),\beta^{-1}_{ML}) \]</p>

<p>이제 다항 계수 w에 대한 사전 분포를 도입할 것이다. 문제의 단순화를 위해서 다음 형태를 지닌 가우시안 분포를 사용할 것이다.
\[ p(w \mid \alpha) = N( w \mid 0,\alpha^{-1}\textbf{I}) = (\frac{\alpha^{\frac{M+1}{2}}}{2\pi})exp(-\frac{\alpha}{2}w^{T}w)\]</p>

<p>식에 대해 설명을 하자면 α는 분포의 정밀도이며 모델 매개변수의 분포를 제어하는 초매개변수이다. 또한 M+1은 m차수 다항식 벡터 w의 원소의 개수이다.</p>

<p>따라서 베이지안 정리에 의해 다음이 성립한다( 자세한 내용은 1.2(2)를 참고)</p>

<p>\[ p(w \mid x,t,\alpha, \beta ) \propto p(t \mid t,w,\beta)p(w \mid \alpha) \]</p>

<p>이제 주어진 데이터에 대해 가장 가능성 높은 w를 찾는 방식으로 w를 결정할 수 있다.
즉, 사후 분포를 최대화하는 방식으로 w를 결정할 수 있다. 이 테크닉을 <b>최대 사후 분포</b>라 한다.</p>

<p>따라서 사후 확률의 최댓값을 찾는 것이 다음 식 값의 최솟값을 찾는 것과 동일함을 알 수 있다.</p>

<p>\[ \frac{\beta}{2}\sum_{n=1}^{N}(y(x_{n},\textbf{w}) - t_{n})^{2} + \frac{\alpha}{2}\textbf{w}^{T}\textbf{w} \]</p>

<p>따라서 사후 분포를 최대화하는 것이 정규화 매개변수가 \( \lambda = \frac{α}{β} \) 로 주어진 식의 정규화된 제곱합 오차 함수(1.1참고)를 최소화하는 것과 동일함을 확인할 수 있다.</p>

<h4 id="베이지안-곡선-피팅">베이지안 곡선 피팅</h4>

<p>비록 사전 분포 p(w | α)를 포함시키긴 했지만, 여전히 w에 대해 점 추정을 하고 있기 때문에 아직은 완벽한 베이지안 방법론을 구사한다고 말할 수 없다. 완전한 베이지안적 접근을 위해서는 확률의 합의 법칙과 곱의 법칙을 일괄적으로 적용해야 한다. 이를 위해서는 모든 w값에 대해 적분을 시행해야 한다. 이러한 주변화가 패턴 인식에서의 베이지안 방법론의 핵심이다.
(주변화에 대하여 좀 더 설명하자면, 여러개의 확률 변수로 구성된 조합 확률 분포에서 한 가지 변수에 대한 확률값을 추정하기 위해 나머지 변수를 모두 적분하여 제거하는 과정을 말한다.)</p>

<p>곡선 피팅 문제의 새로운 변수 x에 대한 표적값 t를 예측하기 위해 예측 분포 p(t|x,X,t)를 구해 보자. 여기서는 매개변수 α 와 β는 고정되어 있으며, 미리 알려졌다고 가정한다.
단순히 말하자면 베이지안 방법은 단지 확률의 합과 곱의 법칙을 계속적으로 적용하는 것이다. 이를 통해 예측 분포를 다음과 같은 형태로 적을 수 있다.</p>

<p>\[ p(t \mid x,\textbf{x},t) = \int p(t \mid x,\textbf{w})p(w \mid \textbf{x},t)dw\]</p>

<p>p(w|x,t)는 매개변수들에 대한 사후 분포이다.
위 식의 적분을 시행하면 예측 분포가 다음의 식과 같이 가우시안 분포로 주어진다는 것을 알 수 있다.</p>

<p>\[ p(t \mid x,\textbf{x},t) = N(t \mid m(x),s^{2}(x)) \]</p>

<p>여기서 예측분포의 평균과 분산이 x에 종속되어 있음을 확인할 수 있다.</p>

<p>여기서 평균과 분산은 다음과 같다</p>

<p>\[ m(x) = \beta \phi (x)^{T}\textbf{S} \sum_{n=1}^{N}\phi(x_{x_{n}})t_{n} \]
\[ s^{2}(x) = \beta^{-1} + \phi(x)^{T} \textbf{S} \phi(x)\]</p>

<p>식에 대해 설명하자면, 분산의 \(\beta^{-1} \)은 타깃 변수의 노이즈로 인한 예측값 t의 불확실성이며 최대가능도 해의 \(\beta^{-1} \)과 같다,
또한 분산의 두 번째 항은 w의 불확실성으로 부터 기인한다.</p>

<p>행렬 S 는 다음처럼 주어진다.</p>

<p>\[\textbf{S}^{-1} = \alpha \textbf{I} + \beta \sum_{n=1}{N} \phi(x_{n})\phi(x_{n})^{T} \]</p>

<p>I 는 단위 행렬이며 ø(x)는 각각의 원소가 i = 0,…,M에 대해 \( \phi_{i}(x) = x^{i} \)인 벡터이다</p>

<p>마지막으로 합성 사인 회귀 문제에 대한 예측 분포의 시각화를 통해 확인해보면서 이해를 돕도록 한다.</p>

<figure>
    <a href="/PRML/11.png" alt="image"><img src="/PRML/11.png" alt="image" /></a>
</figure>

<p>이는 베이지안적 방법을 통해 구한 M = 9인 다항식 곡선 피팅 문제의 예측 분포이다.
빨간색 선은 예측 분포의 평균값을, 그리고 빨간색 영역은 평균값으로부터 ±1 표준 편찻값을 가지는 부분을 표현한 것이다.</p>

:ET