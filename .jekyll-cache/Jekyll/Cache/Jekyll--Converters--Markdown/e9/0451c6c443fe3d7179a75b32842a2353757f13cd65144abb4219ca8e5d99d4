I",<p class="notice">이 글은 <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.</p>

<h4 id="추론과-결정">추론과 결정</h4>

<p>지금까지 분류 문제를 두 개의 단계로 나누어 보았다. 첫 번째는 추론 단계로 훈련 집단을 활용하여 \(p(C_{k} \mid x) \)에 대한 모델을 학습시키는 단계. 두 번째는 결정 단계로 학습된 사후 확률들을 이용해서 최적의 클래스 할당을 시행하는 것이다. 두 가지 문제를 한 번에 풀어내는 방식도 생각해 볼 수 있다. x가 주어졌을 때 결정값을 돌려주는 함수를 직접 학습시키는 것이다. 이러한 함수를 판별함수라고 한다.</p>

<p>결정 문제를 푸는 데는 세 가지 다른 접근법이 있다. 이를 표로 정리하면 다음과 같다.</p>

<figure>
    <a href="/PRML/21.png" alt="image"><img src="/PRML/21.png" alt="image" /></a>
</figure>
<p>하지만 (c)방식을 사용할 경우 사후 확률을 알지 못하게 되는데, 사후 확률을 구하는 것에는 유의미한 여러 가지 이유가 있다.</p>

<p>① 위험의 최소화
손실 행렬의 값들이 때때로 변하는 문제를 고려했을 때, 사후 확률을 알고 있다면 앞 서 설명한 기대 손실 식을 수정함으로써 쉽게 최소 위험 결정 기준을 구할 수 있다. 반면에 판별 함수만 알고 있을 경우에는 손실 행렬 값이 변할 때마다 훈련 집합을 활용하여 분류 문제를 새로 풀어야 할 것이다.</p>

<p>② 거부 옵션
사후 확률을 알고 있으면 주어진 거부 데이터 포인트 비율에 대해 오분류 비율(기대 손실값)을 최소화하는 거부 기준을 쉽게 구할 수 있다.</p>

<p>③ 클래스 사전 확률에 대한 보상
클래스의 불균형을 가지는 데이터에 대해, 각각의 클래스에서 같은 숫자 예시를 선택한 균형 잡힌 데이터 집합을 활용하여 더 정확한 모델을 찾을 수 있다. 하지만 그렇게 할 경우에는 우리가 훈련 집합을 변경한 것에 대한 보상을 적용해야 한다. 이러한 수정된 데이터 집합을 사용하여 사후 확률에 대한 모델을 찾아낸다고 가정할 경우, 사후 확률 식은 베이지안 정리로부터 사전 확률에 비례함을 알 수 있다. 이 예시의 경우 사전 확률로는 각 클래스의 비율을 사용할 수 있다. 따라서 인공의 균형 잡힌 데이터 집합에서 구한 사후 확률을 인공 데이터 집합의 클래스 비율로 나누고, 여기에 우리가 실제로 모델을 적용할 모수 집합의 클래스이 비율을 곱함으로써 수정된 사후 확률을 구할 수 있다. 최종적으로는 새 사후 확률이 합이 1이 되도록 정규화해야 한다. 하지만 직접 판별 함수를 구하는 방식으로 학습을 시킨 경우에는 이러한 수정이 불가능하다.</p>

<p>④ 모델들의 결합
복잡한 응용 사례의 경우에는 하나의 큰 문제를 여러 개의 작은 문제로 나누어서 각각을 분리된 모듈로써 해결하는 것이 바람직한 경우가 있다. 이를 위한 한 가지 쉬운 방법은 각 클래스에 대해서 분리된 데이터 분포가 독립적이라고 가정하는 것이다. (분리된 데이터 \(X_{a},X_{b} \)라고 가정)</p>

<p>\[ p(x_{A},x_{B} \mid C_{k}) = p(x_{A} \mid C_{k})p(x_{B} \mid C_{k})\]</p>

<p>이는 조건부 독립의 성질의 예시다. 분포들이 클래스 Ck에 포함된다는 조건하에 독립적이기 때문이다. 이를 바탕으로 분리된 데이터들이 주어졌을 때의 사후 확률을 다음과 같이 구할 수 있다.
\[ p(C_{k}|x_{A},x_{B}) \propto p(x_{A},x_{B}|C_{k})p(C_{k}) \propto p(x_{A}|C_{k})p(x_{B}|C_{k})p(C_{k}) \propto \frac{p(C_{k}|x_{A})p(C_{k}|x_{B})}{p(C_{k})} \]</p>

<p>클래스 사전 확률 p(Ck)가 필요한데, 이는 데이터 포인트들의 각 클래스별 비율에서부터 쉽게 유추하는 것이 가능하다. 그리고 최종적으로 사후 확률을 정규화하여 합이 1이 되도록 하는 과정이 필요하다.  여기서 보인 특정 조건부 독립 가정은 나이브 베이즈 모델의 예시다. 결합 확률 분포 p(xa,xb)는 보통 나이브 베이즈 모델하에서는 인수분해가 되지 않는다. (조건부 독립 가정 없어도 데이터들을 결합시키는 방법은 이후에 나온다)</p>

<h4 id="회귀에서-손실-함수">회귀에서 손실 함수</h4>

<p>지금까지 분류 문제를 바탕으로 결정 이론에 대해 살펴보았다. 이제부터는 회귀 문제의 경우에 대해 살펴보도록 하자.
회귀 문제의 결정 단계에서는 각각의 x에 대해서 t의 추정값 y(x)를 선택해야 한다. 이 과정에서 손실 L(t,y(x))가 발생한다고 가정해보자. 그러면 평균(기대) 손실은 다음과 같이 주어진다.</p>
:ET