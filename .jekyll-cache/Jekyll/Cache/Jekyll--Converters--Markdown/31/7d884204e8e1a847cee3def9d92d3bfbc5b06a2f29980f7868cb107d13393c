I"B<p class="notice">이 글은 <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.</p>

<p>서로 다른 K개의 값들 중 하나를 취할 수 있는 이산 변수를 표현하기 위해 <b>원 핫 인코딩</b>을 많이 사용한다.
원 핫 인코딩에서는 각각의 변수가 K차원의 벡터 X로 나타내며, \( x_{k} \)값들 중 하나는 1, 나머지 값들은 0으로 설정된다. 예를 들어 4개의 상태를 가질 수 있는 변수가 \( x_{3} = 1\) 이라는 상태를 가졌다면 해당 변수 X를 다음과 같이 표현할 수 있다.
\[ \textbf{X} = (0,0,1,0)^{T}\]</p>

<p>이러한 벡터들은 \( \sum_{k = 1}^{K} x_{k} = 1\)이라는 성질을 만족한다. 만약 우리가 \( x_{k} = 1\)이 될 확률을 \( \mu_{k} \)라고 한다면, X의 분포는 다음과 같이 주어진다.</p>

<p>\[ p(\textbf{X} \mid \mu) = \prod_{k = 1}^{K} \mu_{k}^{x_{k}}  \]</p>

<p>여기서 \( \textbf{ μ } = (\mu_{1},…..,\mu_{K})^{T}\)이며, 매개변수 \( \mu_{k}\)는 \( \mu_{k} \geq 0\)과 \( \sum_{k} \mu_{k} =1 \)이라는 성질을 만족시켜야 한다. (\( \mu_{k} \)는 확률이기 때문에)</p>

<p>이 분포에 대해서 다음의 두 가지를 쉽게 증명할 수 있다.
\[ \sum_{\textbf{X}} p(\textbf{X} \mid \textbf{ μ }) = \sum_{k = 1}^{K} \mu_{k} = 1\]</p>

<p>\[ E(\textbf{X} \mid \textbf{μ}) = \sum_{\textbf{X}} p(\textbf{X} \mid \textbf{ μ })\textbf{X} = (\mu_{1},…,\mu_{k})^{T} = \textbf{μ} \]</p>

<p>N개의 독립적인 관측값 \( \textbf{X}<em>{1},…,\textbf{X}</em>{N} \)을 가진 데이터 집합 D를 고려해 보자. 해당 가능도 함수는 다음의 형태를 가진다.
\[ p(D \mid \textbf{μ} ) = \prod_{n=1}^{N}\prod_{k = 1}^{K} \mu_{k}^{x_{n,k}} = \prod_{k=1}^{K}\mu_{k}^{(\sum_{n}x_{n,k})} = \prod_{k=1}^{K}\mu_{k}^{m_{k}}\]
가능도 함숫값이 K값을 통해서만 N개의 데이터 포인트와 연관되어 있음을 확인할 수 있다.</p>

<p>\[ m_{k} = \sum_{n}x_{n,k}\]</p>

<p>위의 식은 \( x_{k} = 1\)인 관측값의 숫자에 해당한다. 위의 식은 분포의 <b>충분 통계량</b>이라고 한다.(<a href="https://jjomaeng.github.io/blog/충분-통계량/">충분 통계량에 대한 자세한 설명은 여기에 작성하였습니다</a>)</p>

<p>\(\textbf{ μ } \)값의 최대 가능도 해를 찾기 위해서는 \( \mu_{k} \)의 합이 1이어야 한다는 제약 조건하에서 \(lnp(D \mid \textbf{ μ }  )\)의 최댓값을 찾아야 한다. 이를 위해서는 라그랑주 승수 \(\lambda \)를 사용해서 다음 식의 최댓값을 구하면 된다.(<a href="https://jjomaeng.github.io/blog/라그랑주-승수법/">라그랑주 승수법에 대한 자세한 설명은 여기에 작성하였습니다</a>)</p>

<p>\[L(\mu,m,\lambda) = \sum_{k = 1}^{k}m_{k}ln(\mu_{k}) + \lambda(\sum_{k=1}^{K}\mu_{k}-1) \]</p>

<p>먼저, \( \mu_{k}\)에 대해 미분한 뒤 이를 0으로 설정한다.</p>

<figure>
    <a href="/PRML/25.jpeg" alt="image"><img src="/PRML/25.jpeg" alt="image" /></a>
</figure>

<p>그 다음 \(\lambda\)에 대해 미분하여 0이 되는 식을 구한다.</p>

<figure>
    <a href="/PRML/26.jpeg" alt="image"><img src="/PRML/26.jpeg" alt="image" /></a>
</figure>

<p>따라서 최대 가능도의 해는 다음의 형태를 띠게 된다.</p>

<p>\[ \mu_{k}^{ML} = \frac{m_{k}}{N}\]</p>

<p>이는 N개의 관측값 중 \(x_{k} = 1 \)인 경우의 비율이다.</p>

<p>매개변수 \( \textbf{μ} \)와 관측값 숫자 N에 의해 결정되는 수량 \( m_{1},….,m_{k}\)의 결합 분포를 고려해 보자.
가능도 함수에 따라 이는 다음의 형태를 띠게 된다.</p>

<p>위의 식을 <b>다항 분포</b>라고 한다.( <a href="https://jjomaeng.github.io/blog/다항-분포/">이항 분포와 유사한 형태를 띠고 있다는 것을 확인했을 것이다! 이에 대한 자세한 설명은 여기에 적어두었다.</a>)</p>

:ET