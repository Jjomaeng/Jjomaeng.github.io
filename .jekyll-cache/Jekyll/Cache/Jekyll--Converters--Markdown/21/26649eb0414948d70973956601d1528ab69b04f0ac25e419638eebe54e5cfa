I"<p>이 글은 <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>을 읽고 공부한 내용을 작성한 글입니다. 
모든 내용은 책에 포함되어 있는 내용을 기반으로 작성하였습니다.</p>

<p>패턴 인식에서 ‘불확실성’은 측정할 때의 노이즈를 통해서도 발생하고 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.
따라서, 확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해 준다.</p>

<p>예시를 들어보자</p>

<p>이 예시에서는 X,Y라는 두 가지 확률 변수가 존재한다. X는 xi (i = 1,….,M)중 아무 값이나 취할 수 있고 Y는 yj (j = 1,…,L)중 아무 값이나 취할 수 있다. 또한, X와 Y각각에서 표본을 추출하는 시도를 N번 한다고 가정한다.
nij는 X = xi, Y = yj 인 시도 개수를 의미하며, ci는 Y 값과는 상관없이 X= xi인 시도의 숫자, rj는 X값과 상관없이 Y=yj인 시도의 숫자를 의미한다.</p>

<p>X = xi, Y = yj 일 결합 확률은 다음과 같이 표현된다.</p>

<p>\[ p(X = x_{i},Y = y_{i}) = \frac{n_{i,j}}{N} \]</p>

<p>비슷하게 Y값과 무관하게 X가 xi값을 가질 확률을 다음과 같다</p>

<p>\[p(X = x_{i}) =\frac{c_{i}}{N} \]</p>

<p>이 두 식을 이용하여 다음을 도출해 낼 수 있다.</p>

<p>\[p(X = x_{i}) = \sum_{j=1}^{L}p(X = x_{i},Y = y_{j}) \]</p>

<p>이것이 확률의 <b>합의 법칙</b>이다. 여기서 P(X = xi)는 주변 확률이라 불린다.</p>

<table>
  <tbody>
    <tr>
      <td>여기서 X = xi인 사례들만 고려해보자. 그들 중에서 Y = yi인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 p(Y = yi</td>
      <td>X = xi)로 적을 수 있으며 이를 <b>조건부 확률</b>이라고 부른다</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>\[p(Y = y_{i}</td>
      <td>X = x_{i}) = \frac{n_{i,j}}{c_{i} \]</td>
    </tr>
  </tbody>
</table>

<p>지금까지의 식을 이용해서 다음의 관계를 도출할 수 있다.</p>
:ET